{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4cbec299a5d4f64",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "* #TODO: INSERT LINK TO WANDB VIEW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1fcc78251ae773",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae74b556f3aff49",
   "metadata": {},
   "source": [
    "#### Install dependencies\n",
    "\n",
    "* **torch**: PyTorch framework for the creation of neural networks\n",
    "* **lightning**: Lightning wrapper for pytorch for simple network training\n",
    "* **huggingface_hub**: HuggingFace hub for downloading word vectors\n",
    "* **datasets**: HuggingFace datasets to download and load the data set\n",
    "* **wandb**: Weights & Biases for experiment tracking\n",
    "* **fasttext**: Word embedding library\n",
    "* **nltk**: Natural Language Toolkit used for word tokenization\n",
    "* **torchmetrics**: Extension to lightning to compute model metrics\n",
    "* **matplotlib**: Display confusion matrix plot\n",
    "* **pandas**: Create error analysis in tabular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f5c188a84c79a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from unicodedata import bidirectional\n",
    "\n",
    "%pip install -q torch lightning huggingface_hub datasets wandb nltk torchmetrics matplotlib pandas\n",
    "\n",
    "if sys.platform == 'win32': # Windows requires different fasttext implementation\n",
    "    %pip install -q fasttext-wheel\n",
    "else: \n",
    "    %pip install -q fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b435e83550d40",
   "metadata": {},
   "source": [
    "Do all the imports needed in this project, but keep them separate depending on the part of the notebook that uses them. Reason: Makes reading easier in later sections if done subsequently, but don't users to import everything if they just want to run some specific cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6c5769e426a79",
   "metadata": {},
   "source": [
    "##### pytorch & lightning"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e0c3ad68f73131c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:47:50.135734Z",
     "start_time": "2025-04-05T08:47:06.902121Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import torchmetrics"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\git\\NLP_FS25\\.env3\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "28a8be01f6acc709",
   "metadata": {},
   "source": [
    "##### Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6c55b396bb8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from datasets import Dataset as HFDataset\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cbccf2e9344a44",
   "metadata": {},
   "source": [
    "##### Tokenization & Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abfecdc173a6fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee75b073f883d",
   "metadata": {},
   "source": "##### Evaluation"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e378a871147cb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d523ec31804506",
   "metadata": {},
   "source": [
    "##### Python Builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccac58d97e06351",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90dec31f8030c9",
   "metadata": {},
   "source": [
    "##### Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c62074d7822dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b696ef4250c380a0",
   "metadata": {},
   "source": [
    "#### Load dataset\n",
    "\n",
    "Use the pre-defined method to load the dataset and do the train and validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad899724a20482d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8741 1000 1221\n"
     ]
    }
   ],
   "source": [
    "train: HFDataset = load_dataset(\"tau/commonsense_qa\", split=\"train[:-1000]\")\n",
    "valid: HFDataset = load_dataset(\"tau/commonsense_qa\", split=\"train[-1000:]\")\n",
    "test: HFDataset = load_dataset(\"tau/commonsense_qa\", split=\"validation\")\n",
    "\n",
    "print(len(train), len(valid), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc78217c5ed1f84",
   "metadata": {},
   "source": [
    "#### Setup Weights & Biases\n",
    "\n",
    "Login to weights and biases to enable experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9bc41bae4172979",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: \u001B[32m\u001B[41mERROR\u001B[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mschurtenberger-david\u001B[0m (\u001B[33mdavid-schurtenberger\u001B[0m) to \u001B[32mhttps://api.wandb.ai\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b635a3413d69a3fc",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "#### Vocabulary/Embedding\n",
    "\n",
    "* I used **FastText** word embeddings. Reason:\n",
    "\n",
    "    * Mentioned in class that FastText is superior to other embedding models\n",
    "    * Can handle unknown words, due to subword embeddings\n",
    "\n",
    "* I will be working with the [Facebook English Fasttext embeddings](https://huggingface.co/facebook/fasttext-en-vectors). Reason:\n",
    "\n",
    "    * They are directly downloadable from *HuggingFace hub*\n",
    "    * The embed words from the English language, which is the scope of this project\n",
    "\n",
    "* This choice influences decisions in the following pre-processing steps.\n",
    "\n",
    "#### Format cleaning (e.g. html-extracted text)\n",
    "\n",
    "* No format cleaning is performed. Reason:\n",
    "    \n",
    "    * We are working with a carefully assembled and standardized dataset used in model benchmarking\n",
    "\n",
    "#### Tokenization\n",
    "\n",
    "* *word_tokenizer* from the **nltk** library will be used. Reason:\n",
    "\n",
    "    * Works well for the English language\n",
    "    * It splits punctuation from text, which matches the tokens the fasttext word vectors were trained on\n",
    "\n",
    "#### Lowercasing, stemming, lemmatizing, stopword/punctuation removal\n",
    "\n",
    "* **Lowercasing**: Tokenized words are lower-cased. Reason:\n",
    "\n",
    "    * Keep vocabulary small\n",
    "    * The FastText model from facebook was trained on uppercase, so it could handle uppercased words, but using lower-cased also minimized out-of-vocabulary words\n",
    "\n",
    "* **Stemming**: No stemming is used. Reason:\n",
    "\n",
    "    * The embedding model was not trained on word stems and therefore no stemming is carried out\n",
    "    \n",
    "* **Lemmatizing**: The word tokens to be embedded will not be lemmatized. Reason:\n",
    " \n",
    "    * The embedding model was trained on un-lemmatized words \n",
    "    * The n-gram encoding of the words used in fasttext preserves sub-word information\n",
    "\n",
    "* **Stopword/Punctudation removal**: No stopword, punctuation removal. Reason:\n",
    "\n",
    "    * Stopwords and punctuation can be crucial for question answering\n",
    "    * Questions are short, therefore minimize loss of information\n",
    "\n",
    "#### Removal of unknown/other words\n",
    "\n",
    "* No unknown or other words are removed. Reason:\n",
    "\n",
    "    * FastText can build embeddings from a words n-gram vectors\n",
    "    * The encounter of unknown words is not expected\n",
    "\n",
    "#### Truncation\n",
    "\n",
    "* Input will not be truncated. Reason:\n",
    "\n",
    "    * Longest question yields an embedded tensor of shape **67x300**\n",
    "    * Depending on input format, the processing of a little over 67 timesteps is deemed to be feasible\n",
    "\n",
    "#### Feature selection\n",
    "\n",
    "* **question**, **choices** and **answerKey** were selected. Reason:\n",
    "\n",
    "    * *questionConcept* seemed interesting, but this feature often simply contains a word from the question\n",
    "    * The end this feature was left out in order not to give too much emphasis to a single word that does likely not help answering the question at all\n",
    "\n",
    "#### Input format: how is data passed to the model?\n",
    "\n",
    "###### Classifier\n",
    "\n",
    "* Tensor with shape **(1800,)**.\n",
    "\n",
    "* The first 300 elements are the averages of the embedded question tokens, next are 300 elements for every embedded and averaged answer vector from answer option 'A' to 'E'. Reason:\n",
    "    \n",
    "    * Average of question vectors, because it is a good tradeoff between information retention and input  dimension for the classifier\n",
    "    * Question vector is before answer vectors because \"Q&A\" also has question first, then answers\n",
    "    * Answers are arranged from 'A' to 'E' because of alphabetical order\n",
    "    * Average of the answer embeddings because answers can consist of multiple words and may yield multiple embedding vectors\n",
    "\n",
    "###### RNN + Classifier\n",
    "\n",
    "* Tensor with shape **(5, N + 2, 300)**\n",
    "\n",
    "* The average of the answer embeddings, are concatenated to the question with sequence length *N* with a separator token in between. Reason:\n",
    "\n",
    "    * Question preprended to every answer because every resulting hidden vector has the same amount of question and answer encoded\n",
    "    * Average of answer embeddings because every choice has the same amount of time steps in answer encoding\n",
    "    * Separator token from character **¦** because model can learn when question stops and answer start and character is not used in dataset\n",
    "    * Answer embeddings after question embeddings, because \"Q&A\" also has question first, then answer.    \n",
    "\n",
    "#### Label format: what should the model predict?\n",
    "\n",
    "* Tensor with shape **(5,)**. Reason:\n",
    "\n",
    "    * Answers choices ('A' through 'E') are encoded on an index in the vector (0 through 4)\n",
    "    * Classifier at last model step predicts likelihood of each class/choice\n",
    "\n",
    "#### Train/valid/test splits\n",
    "\n",
    "* Last *1000* entries of train set are validation set. Validation set is test set. Reason:\n",
    "\n",
    "    * Required in assignment\n",
    "\n",
    "#### Batching, padding\n",
    "\n",
    "* Batch size is **512** (both architectures). Reason:\n",
    "\n",
    "    * Experimentation showed that both datasets fully fit on GPU memory on *gpuhub*\n",
    "    * Choose *512* as batch size to keep doing stochastic gradient descent\n",
    "    * *gpuhub* does not always allocate same amount of GPU memory, but batch size *512* never used more than 80% of allocated memory\n",
    "\n",
    "* No padding for *Classifier* model. Reason:\n",
    "\n",
    "    * Input is always of the same size\n",
    "    \n",
    "* Padding to maximum sequence length of batch for *RNN+Classifier* model. Reason:\n",
    "\n",
    "    * Question tensors are of variable length\n",
    "    * Same sequence length needed for every tensor of a batch, to compute one single tensor\n",
    "    * Padded tensor can be packed to keep parallel processing on GPU without executing timesteps for padding vectors\n",
    "    * Implemented in **rnn_collate_fn**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5eb8363eacb78",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "\n",
    "Create method to tokenize and lowercase a given text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b71c0f47430aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"punkt_tab\")\n",
    "\n",
    "def tokenize(text: str) -> list[str]:\n",
    "    return [w.lower() for w in nltk.word_tokenize(text, language=\"english\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d42f6a99035f0",
   "metadata": {},
   "source": [
    "### Word embeddings\n",
    "\n",
    "Download the english fasttext word vectors and load their model into the variable *wv_model*\n",
    "\n",
    "Create a function to embed a list of tokenized words and return them as a list of pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1403d38e9ae55f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hf_hub_download(\"facebook/fasttext-en-vectors\", \"model.bin\")\n",
    "wv_model = fasttext.load_model(model_path)\n",
    "\n",
    "def get_embeddings_for_tokens(tokens: list[str]):\n",
    "    return torch.stack([torch.tensor(wv_model[t]) for t in tokens])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762f05a64aba4571",
   "metadata": {},
   "source": [
    "### Data Loading and Formatting\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Introduce a type for functions that transform question and answer tensors into combined tensors for both model architectures",
   "id": "8315f9983ca8dd7a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2dfba7d95d0678",
   "metadata": {},
   "outputs": [],
   "source": "TransformMethod = Callable[[torch.Tensor, list[torch.Tensor]], torch.Tensor]"
  },
  {
   "cell_type": "markdown",
   "id": "aa78299e9e366c1d",
   "metadata": {},
   "source": [
    "Create a separator token from a character that is known to the word vector model, but unused in the train, valid and test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40a64f78521705ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def char_not_in_huggingface_dataset(char: str, dataset: HFDataset) -> bool:\n",
    "    for datapoint in dataset:\n",
    "        if char in datapoint[\"question\"] or any(char in c for c in datapoint[\"choices\"][\"text\"]):\n",
    "            return False\n",
    "    return True\n",
    "    \n",
    "\n",
    "separator = \"¦\"\n",
    "assert separator in wv_model # Check if placeholder is a known token in the model\n",
    "assert char_not_in_huggingface_dataset(separator, train)\n",
    "assert char_not_in_huggingface_dataset(separator, valid)\n",
    "assert char_not_in_huggingface_dataset(separator, test)\n",
    "\n",
    "SEP_TOKEN = torch.tensor(wv_model[separator])\n",
    "SEP_TOKEN.shape"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a **pytorch** *Dataset* class in which the HuggingFace dataset is loaded and preprocessed. This allows for an easy integration with a *DataLoader* afterward.",
   "id": "5265749ca521018b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beff391944e99b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_INDEX_MAPPING = {\n",
    "    \"A\": 0,\n",
    "    \"B\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3,\n",
    "    \"E\": 4,\n",
    "}\n",
    "\n",
    "class CommonsenseQADataset(Dataset):    \n",
    "    def __init__(self, dataset: HFDataset, transform: TransformMethod):\n",
    "        self.dataset: list[dict[str, torch.tensor | list[torch.tensor]]] = []\n",
    "        self._target_transform = transform\n",
    "        self._transform_hugging_face_dataset(dataset)\n",
    "    \n",
    "    def _transform_hugging_face_dataset(self, dataset: HFDataset):\n",
    "        self.dataset.extend([{\n",
    "            \"feature\": self._target_transform(\n",
    "                get_embeddings_for_tokens(tokenize(entry[\"question\"])),\n",
    "                [get_embeddings_for_tokens(tokenize(choice)) for choice in entry[\"choices\"][\"text\"]],\n",
    "            ),\n",
    "            \"label\": torch.tensor(KEY_INDEX_MAPPING[entry[\"answerKey\"]]),\n",
    "        } for entry in dataset])\n",
    "        if len(self.dataset) != len(dataset):\n",
    "            raise RuntimeError(\"Converted dataset is not full reflection of source data\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.dataset[idx]\n",
    "        return data_point[\"feature\"], data_point[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cc3469965c8b86",
   "metadata": {},
   "source": [
    "Transform function for **Classifier** architecture\n",
    "\n",
    "* Function input: Question-tensor (N, 300) and answer-tensor (5, 300)\n",
    "* Function output: Classifier-tensor (1800,)\n",
    "    * Average of question vectors yields tensor with shape (300,)\n",
    "    * Question vector and answer vectors are concatenated (300,) + (5, 300) = (1800,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1384f3a7738a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_target_transform(question: torch.Tensor, answers: list[torch.Tensor]) -> torch.Tensor:\n",
    "    return torch.cat((question.mean(dim=0), *(a.mean(dim=0) for a in answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b65a982633864dd",
   "metadata": {},
   "source": [
    "Transform function for **RNN + Classifier** architecture\n",
    "\n",
    "* Function input: Question-tensor (N, 300) and answer-tensor (5, 300)\n",
    "* Function output: RNN-tensor (5, N + 2, 300) with N question vectors, 1 SEP_TOKEN vectors separating the question from the answer and 1 answer vector. For every answer individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7278eaffa9f7bae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_target_transform(question: torch.Tensor, answers: list[torch.Tensor]) -> torch.Tensor:\n",
    "    concatenated = [torch.cat((question, SEP_TOKEN.unsqueeze(0), answer.mean(dim=0).unsqueeze(0))) for answer in answers]\n",
    "    return torch.stack(concatenated, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6844adea2617f1eb",
   "metadata": {},
   "source": [
    "Collate function for **RNN + Classifier** architecture\n",
    "\n",
    "* Function input: List of length *batch_size* (*B*) of tuples of transformed tensors and labels\n",
    "    * Shape transformed tensors (5, S, 300) (S = sequence length)\n",
    "* Function output: Forward-tensor (B, 5, MAX_S, 300)\n",
    "    * Sorted by initial sequence length to ensure compatibility with *pack_padded_sequence*"
   ]
  },
  {
   "cell_type": "code",
   "id": "57768745de06f997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-05T08:47:50.162961Z",
     "start_time": "2025-04-05T08:47:50.153142Z"
    }
   },
   "source": [
    "def rnn_collate_fn(batch: list[tuple[torch.Tensor, torch.Tensor]]):\n",
    "    questions, labels = zip(*batch)\n",
    "    \n",
    "    lengths = torch.tensor([q.shape[1] for q in questions])\n",
    "    max_len = lengths.max()\n",
    "    padded_questions = torch.stack([torch.nn.functional.pad(q, (0, 0, 0, max_len - l)) for q, l in zip(questions, lengths)])\n",
    "    \n",
    "    lengths, perm_idx = torch.tensor(lengths).sort(descending=True)\n",
    "    padded_questions = padded_questions[perm_idx]\n",
    "    labels = torch.stack(labels)[perm_idx]\n",
    "    \n",
    "    return padded_questions, lengths, labels"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "1e4941497bdf4f65",
   "metadata": {},
   "source": [
    "Transform HuggingFace datasets to pytorch Datasets for both Classifier and RNN+Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16ae26b8c01da94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classifier = CommonsenseQADataset(train, classifier_target_transform)\n",
    "valid_classifier = CommonsenseQADataset(valid, classifier_target_transform)\n",
    "test_classifier = CommonsenseQADataset(test, classifier_target_transform)\n",
    "\n",
    "\n",
    "train_rnn = CommonsenseQADataset(train, rnn_target_transform)\n",
    "valid_rnn = CommonsenseQADataset(valid, rnn_target_transform)\n",
    "test_rnn = CommonsenseQADataset(test, rnn_target_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5a1ae791e74c08",
   "metadata": {},
   "source": "The following routine was used to determine the best batch size. It was only run after model architecture definition and processing was implemented to determine the best batch size to use."
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b41bb4779fb9290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_size_finder(data: Dataset, model: nn.Module, collate_fn = None, max_memory_usage=0.8) -> tuple[int, float]:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    if not device == \"cuda\":\n",
    "        raise RuntimeError(\"Can only be run on gpu\")\n",
    "    batch_size, memory_usage = 16, 0\n",
    "    model.to(device)\n",
    "    \n",
    "    while True:\n",
    "        loader = torch.utils.data.DataLoader(data, batch_size=batch_size, collate_fn=collate_fn, num_workers=4)\n",
    "        inputs = nn.utils.rnn.PackedSequence(torch.tensor(()), torch.tensor(())) if collate_fn else torch.tensor([])\n",
    "        labels = torch.tensor([])\n",
    "        for i, l in loader:\n",
    "            if isinstance(i, nn.utils.rnn.PackedSequence):\n",
    "                if i.batch_sizes.shape > inputs.batch_sizes.shape:\n",
    "                    inputs, labels = i, l                  \n",
    "            elif i.shape > inputs.shape:\n",
    "                inputs, labels = i, l\n",
    "        try:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            _ = model(inputs)\n",
    "            \n",
    "            # Check memory usage\n",
    "            mem_allocated = torch.cuda.memory_allocated(device)\n",
    "            mem_reserved = torch.cuda.memory_reserved(device)\n",
    "            mem_usage = mem_allocated / mem_reserved\n",
    "\n",
    "            print(f\"Batch Size: {batch_size}, Memory Usage: {mem_usage:%}\")\n",
    "\n",
    "            if mem_usage <= memory_usage:\n",
    "                return batch_size // 2, memory_usage\n",
    "            \n",
    "            if mem_usage >= max_memory_usage:\n",
    "                return batch_size, mem_usage\n",
    "           \n",
    "            batch_size *= 2\n",
    "            memory_usage = mem_usage\n",
    "        \n",
    "        except RuntimeError as e:\n",
    "            if 'out of memory' in str(e):\n",
    "                return batch_size // 2, memory_usage\n",
    "            raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c78934ccac35531",
   "metadata": {},
   "source": "Determine the optimal batch size for both Classifier and RNN+Classifier models. Optimal batch size was chosen to be when 80% of memory is used. -> As mentioned, the entire dataset fit onto GPU memory, using model hyperparameters that lead to most parameters. A batch size of 512 was chosen to have about 18 training steps and keep doing stochastic gradient descent."
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f965e29192a6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN_DIM_CLASSIFIER = 4096\n",
    "# BATCH_SIZE_CLASSIFIER, memory_usage = batch_size_finder(train_classifier, Classifier(hidden_dim=HIDDEN_DIM_CLASSIFIER))\n",
    "# print(f\"Batch Size: {BATCH_SIZE_CLASSIFIER} @ {memory_usage:%} memory usage\")\n",
    "BATCH_SIZE_CLASSIFIER = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4abd0c35b8861437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIDDEN_DIM_RNN_LINEAR, HIDDEN_DIM_RNN_GRU, BIDIRECTIONAL = 2048, 256, True\n",
    "# BATCH_SIZE_RNN, memory_usage = batch_size_finder(train_rnn, RNNClassifier(hidden_dim_linear=HIDDEN_DIM_RNN_LINEAR, hidden_dim_gru=HIDDEN_DIM_RNN_GRU, bidirectional=BIDIRECTIONAL), rnn_collate_fn)\n",
    "# print(f\"Batch Size: {BATCH_SIZE_RNN} @ {memory_usage:%} memory usage\")\n",
    "BATCH_SIZE_RNN = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d659013d41df134",
   "metadata": {},
   "source": [
    "Instantiate data loaders for both model types\n",
    "\n",
    "* Shuffle training data. Reason: Minimize risk of learning inhibition due to sorted training data\n",
    "* Include collate function for RNN. Reason: Create single tensor from tensors with different sequence lenght in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9eca8e459cf146cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_classifier = torch.utils.data.DataLoader(train_classifier, batch_size=BATCH_SIZE_CLASSIFIER, shuffle=True, num_workers=4)\n",
    "valid_loader_classifier = torch.utils.data.DataLoader(valid_classifier, batch_size=BATCH_SIZE_CLASSIFIER, num_workers=4)\n",
    "test_loader_classifier = torch.utils.data.DataLoader(test_classifier, batch_size=BATCH_SIZE_CLASSIFIER, num_workers=4)\n",
    "\n",
    "train_loader_rnn = torch.utils.data.DataLoader(train_rnn, batch_size=BATCH_SIZE_RNN, collate_fn=rnn_collate_fn, shuffle=True, num_workers=4)\n",
    "valid_loader_rnn = torch.utils.data.DataLoader(valid_rnn, batch_size=BATCH_SIZE_RNN, collate_fn=rnn_collate_fn, num_workers=4)\n",
    "test_loader_rnn = torch.utils.data.DataLoader(test_rnn, batch_size=BATCH_SIZE_RNN, collate_fn=rnn_collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554586163be5eb6b",
   "metadata": {},
   "source": [
    "# 1. Architecture: Classifier\n",
    "## WordEmbeddings &rarr; Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26a4c41b4d0171",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "#### Network architecture (layers, dims, nonlinearities, regularizations, normalizations, classifier)\n",
    "\n",
    "* **Layers**\n",
    "    * Two linear layers. Reason:\n",
    "        * Required in assignment\n",
    "    \n",
    "* **Dimensions**\n",
    "    * First layer: `input_dim = 1800`, `output_dim = 512`. Reason:\n",
    "        * Input dim given from data preprocessing\n",
    "        * Output dim determined through hyperparameter sweeps\n",
    "    * Second Layer: `input_dim = 512`, `output_dim = 5`. Reason: \n",
    "        * Input dim must match output dim of layer 1\n",
    "        * Output dim given from problem to be solved with 5 classes\n",
    "                \n",
    "* **Nonlinearities**\n",
    "    * RELU-nonlinearity in between the two layers. Reason:\n",
    "        * Required in assignment\n",
    "\n",
    "* **Regularizations**\n",
    "    * Dropout with probability of `p = 0.2` after output activation of first layer. Reason:\n",
    "        * Ensure some information redundancy in hidden layer of classifier\n",
    " \n",
    "* **Normalizations**\n",
    "    * No normalization was used. Reason:\n",
    "        * Not required to be used\n",
    "        * Extra computation of normalization was deemed not to be worth it\n",
    "\n",
    "* **Classifier**\n",
    "    * A multiclass classifier was used. Reason:\n",
    "        * The task is inherently a multiclass classification task with 5 classes\n",
    "        * The model was expected to perform better having to choose one class given the information of all classes at once instead of binary classification with only information of the question and one answer at a time.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40c1e0798eb9f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim: int = 1800, \n",
    "            hidden_dim: int = 2048, \n",
    "            output_dim: int = 5, \n",
    "            dropout: float = 0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, _=None) -> torch.Tensor:\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.dropout(out)\n",
    "        return self.fc2(out)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        self.fc1.reset_parameters()\n",
    "        self.fc2.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d04ba2f9898ed",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "#### Loss, optimizer\n",
    "* **Loss function**: CrossEntropyLoss. Reason:\n",
    "    * Architecture is designed as a multiclass classifier\n",
    "\n",
    "* **Optimizer**: AdamW. Reason:\n",
    "    * Good experience with AdamW in past projects\n",
    "    * Adaptive learning rates based on gradients\n",
    "\n",
    "#### Experiment design (model/optimizer/loss variants, hyperparameters)\n",
    "\n",
    "* **Model/Optimizer/Loss variants**: No combinations were tried. Reason:\n",
    "    * CrossEntropyLoss is only meaningful loss function for this problem\n",
    "    * Binary classifier model was not tried because of time constraints\n",
    "    * AdamW optimizer was deemed to be superior (in hindsight most likely a false assumption)\n",
    "\n",
    "* **Hyperparameters**: The following parameters were chosen for the baseline model\n",
    "    * learning rate: 1e-4\n",
    "    * hidden dimension: 2048\n",
    "    * training epochs: 100\n",
    "    * adam epsilon: 1e-8\n",
    "    * dropout: 0.1\n",
    "    * weight decay: 0.0\n",
    "    * scheduler start percentage: 0.1\n",
    "    * **Goal**: Maximize validation accuracy\n",
    "    * Reason:\n",
    "        * Baseline hyperparameters were chosen based on experience and sensibility\n",
    "        * Maximizing validation accuracy was chosen because as many questions as possible should be answered correctly, no matter how wrong the others are\n",
    "\n",
    "#### Number of training runs\n",
    "\n",
    "* 1 run on baseline model. Reason:\n",
    "    * Have comparable result on hyperparameters that were deemed good at implementation time\n",
    "* 50 runs in first broad sweep. Reason:\n",
    "    * Broad range of values for most hyperparameters to determine which values are promising\n",
    "    * Sweep using *Bayes* method to automatically tune in on promising parameter combinations\n",
    "* 30 runs in second narrow sweep. Reason:\n",
    "    * Determine the best hyperparameter combination on narrower options\n",
    "    * Use narrow band of values in ranges deemed promising in first hyperparameter sweep\n",
    "\n",
    "#### Model checkpointing\n",
    "\n",
    "* Best and last epoch for every run is checkpointed. Reason:\n",
    "    * Keep best run for possible later test set evaluation\n",
    "    * Keep last run for possible later elongated training or fine-tuning\n",
    "\n",
    "#### Early stopping\n",
    "\n",
    "* Early stopping after 20 epochs of no improvement on validation accuracy. Reason:\n",
    "    * Do not waste computation\n",
    "    * Model accuracy was seen to further deteriorate after more than 20 epochs of no improvement\n",
    "\n",
    "#### Sweeps\n",
    "\n",
    "* Two sweeps, one broad sweep and one narrow sweep. Reason:\n",
    "    * Determined to be the most efficient method of hyperparameter optimization\n",
    "    * *Bayes* sweep method is good tradeoff of computation efficiency and testing for of full range of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e0f3dff45f259",
   "metadata": {},
   "source": "Create a LightningModule subclass that takes the model and all hyperparameters as arguments. With this class training can be simplified using the pytorch lightning framework. This class will also be reused for the RNN+Classifier model.\n"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "130d3b7479e8a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CqaModule(L.LightningModule):\n",
    "    def __init__(\n",
    "            self, \n",
    "            model: Classifier,\n",
    "            loss_function,\n",
    "            output_dim=5,\n",
    "            **kwargs        \n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(kwargs)\n",
    "        self.model = model\n",
    "        self.model.reset_parameters()\n",
    "        \n",
    "        self.loss_fn = loss_function()\n",
    "        \n",
    "        self._train_acc = torchmetrics.Accuracy(\"multiclass\", num_classes=output_dim)\n",
    "        self._train_loss = []\n",
    "        self._valid_acc = torchmetrics.Accuracy(\"multiclass\", num_classes=output_dim)\n",
    "        self._valid_loss = []\n",
    "        self._max_valid_acc = 0\n",
    "        self._test_acc = torchmetrics.Accuracy(\"multiclass\", num_classes=output_dim)\n",
    "        self._test_preds = []\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, lengths: torch.Tensor = None) -> torch.Tensor:\n",
    "        return self.model(x, lengths)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        y = batch[-1]\n",
    "        y_hat = self(*batch[:-1])\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self._train_loss.append(loss)\n",
    "        self._train_acc(y_hat.argmax(-1), y)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        y = batch[-1]\n",
    "        y_hat = self(*batch[:-1])\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        self._valid_loss.append(loss)\n",
    "        self._valid_acc(y_hat.argmax(-1), y)\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        loss = torch.stack(self._train_loss).mean()\n",
    "        self.log_dict({'train_loss': loss, 'train_acc': self._train_acc.compute()}, prog_bar=True)\n",
    "        self._train_loss.clear()\n",
    "        self._train_acc.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        loss = torch.stack(self._valid_loss).mean()\n",
    "        valid_acc = self._valid_acc.compute()\n",
    "        self._max_valid_acc = max(self._max_valid_acc, valid_acc)\n",
    "        self.log_dict({'valid_loss': loss, 'valid_acc': valid_acc, 'max_valid_acc': self._max_valid_acc}, prog_bar=True)\n",
    "        self._valid_loss.clear()\n",
    "        self._valid_acc.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.AdamW(\n",
    "            self.parameters(), \n",
    "            lr=self.hparams.lr, \n",
    "            eps=self.hparams.adam_e, \n",
    "            weight_decay=self.hparams.wd\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, self.hparams.lr, epochs=self.hparams.epochs, steps_per_epoch=self.hparams.steps_per_epoch, pct_start=self.hparams.pct_start, div_factor=1000, final_div_factor=10000)\n",
    "        return {\"optimizer\": optim, \"lr_scheduler\": scheduler}\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fee839789148a2",
   "metadata": {},
   "source": [
    "#### Training routine\n",
    "\n",
    "Define the function **train_classifier** which describes the training routine for the classifier model using the **Trainer** class of *lightning* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc9afa3b8d2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightning_train_classifier(config, logger, *callbacks):\n",
    "    L.seed_everything(42)\n",
    "    model = CqaModule(\n",
    "        Classifier(hidden_dim=config.get(\"hd_cls\"), dropout=config.get(\"drp\")),\n",
    "        nn.CrossEntropyLoss,\n",
    "        **config\n",
    "    )\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config.get(\"epochs\"),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        callbacks=list(callbacks),\n",
    "        logger=logger,\n",
    "    )\n",
    "    trainer.fit(model, train_loader_classifier, valid_loader_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e5be5719640b0",
   "metadata": {},
   "source": [
    "#### Run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4023fb40f5bec5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_name(model_name: str, config: dict):\n",
    "    params = []\n",
    "    for k, v in config.items():\n",
    "        if isinstance(v, float):\n",
    "            params.append(f\"{k}={v:.5f}\")\n",
    "        else:\n",
    "            params.append(f\"{k}={v}\")\n",
    "    return f\"{model_name}_{'_'.join(params)}_{time.strftime('%y%m%d%H%M%S')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cae337d032af7a",
   "metadata": {},
   "source": [
    "Baseline parameters for Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fced576b1c3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Classifier_Baseline\"\n",
    "config = dict(\n",
    "    lr=1e-4,\n",
    "    hd_cls=2048,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=len(train_loader_classifier),\n",
    "    adam_e=1e-8,\n",
    "    drp=0.1,\n",
    "    wd=0.0,\n",
    "    pct_start=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f350873e1806d",
   "metadata": {},
   "source": "#### Checkpointing"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123befecb9a8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"./lightning_checkpoints\",\n",
    "    filename=get_run_name(MODEL_NAME, config) + \"-{epoch:02d}-{valid_acc:.2f}\",\n",
    "    monitor=\"valid_acc\",\n",
    "    save_last=True,\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a112c21ae9f586",
   "metadata": {},
   "source": "#### Early Stopping"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75151dc056ffb566",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = L.pytorch.callbacks.EarlyStopping(\n",
    "    monitor=\"valid_acc\",\n",
    "    patience=20,\n",
    "    mode=\"max\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5710a3c3640df3",
   "metadata": {},
   "source": [
    "Execute training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b043c76c9360d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(\n",
    "    entity=\"david-schurtenberger\",\n",
    "    project=\"NLP_Project_1\",\n",
    "    name=get_run_name(MODEL_NAME, config),\n",
    "    config=config,\n",
    ") as run:\n",
    "    wandb_logger = WandbLogger(project=\"NLP_Project_1\")\n",
    "    lightning_train_classifier(run.config, wandb_logger, checkpoint_callback, early_stopping_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3313074f11e44e07",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1267cbffa1e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Classifier\"\n",
    "def classifier_sweep(config=None):\n",
    "    with wandb.init(config=config) as run:\n",
    "        config = wandb.config\n",
    "        run.name = get_run_name(MODEL_NAME, config)\n",
    "        checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "            dirpath=\"./lightning_checkpoints\",\n",
    "            filename=get_run_name(MODEL_NAME, config) + \"-{epoch:02d}-{valid_acc:.2f}\",\n",
    "            monitor=\"valid_acc\",\n",
    "            save_last=True,\n",
    "            mode=\"max\"\n",
    "        )\n",
    "        early_stopping_callback = L.pytorch.callbacks.EarlyStopping(\n",
    "            monitor=\"valid_acc\",\n",
    "            patience=20,\n",
    "            mode=\"max\",\n",
    "        )\n",
    "        wandb_logger = WandbLogger(log_model=True)\n",
    "        lightning_train_classifier(config, wandb_logger, checkpoint_callback, early_stopping_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea117bb339c0e7",
   "metadata": {},
   "source": [
    "Broad sweep\n",
    "\n",
    "Use a broad range of values for most hyperparameters to get most promising values and combination of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53301ec0de017953",
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_sweep_parameters = {\n",
    "        \"lr\": {\"values\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"hd_cls\": {\"values\": [256, 512, 1024, 2048, 4096]},\n",
    "        \"wd\": {\"min\": 0.0, \"max\": 1e-3},\n",
    "        \"adam_e\": {\"value\": 1e-8},\n",
    "        \"drp\": {\"min\": 0.0, \"max\": 0.3},\n",
    "        \"pct_start\": {\"values\": [0.1, 0.2, 0.3]},\n",
    "        \"epochs\": {\"value\": 100},\n",
    "        \"steps_per_epoch\": {\"value\": len(train_loader_classifier)},\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64f18d807de5fd7",
   "metadata": {},
   "source": [
    "Narrow sweep\n",
    "\n",
    "With results from broad sweep, choose closer ranges of values to determine overall best combination of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da4032044e3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_sweep_parameters = {\n",
    "        \"lr\": {\"values\": [3e-3, 1e-2, 3e-2]}, # equivalence to [1e-2.5, 1e-2, 1e-1.5]\n",
    "        \"hd_cls\": {\"value\": 512},\n",
    "        \"wd\": {\"values\": [3e-4, 1e-3, 3e-3, 1e-2]}, # equivalence to [1e-3.5, 1e-3, 1e-2.5, 1e-2]\n",
    "        \"adam_e\": {\"values\": [1e-9, 1e-8, 1e-7]},\n",
    "        \"drp\": {\"values\": [0.2, 0.25, 0.3]},\n",
    "        \"pct_start\": {\"value\": 0.3},\n",
    "        \"epochs\": {\"value\": 100},\n",
    "        \"steps_per_epoch\": {\"value\": len(train_loader_classifier)},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e9434bb5ec197",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"ClassifierSweep_Narrow\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"max_valid_acc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": narrow_sweep_parameters,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76663298b254e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(\n",
    "    sweep=sweep_config, \n",
    "    entity=\"david-schurtenberger\",\n",
    "    project=\"NLP_Project_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4d55ac009eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id=sweep_id, function=classifier_sweep, count=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc92c65c32b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.api.stop_sweep(sweep_id)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "After all sweeps, and run analysis the following run was determined to be best",
   "id": "4c279b2d86506c4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "checkpoint_path = \"lightning_checkpoints/Classifier_adam_e=0.00000_drp=0.20000_epochs=100_hd_cls=512_lr=0.03000_pct_start=0.30000_steps_per_epoch=18_wd=0.00030_250330212720-epoch=16-val_acc=0.00.ckpt\"",
   "id": "14dd4604dcb51131"
  },
  {
   "cell_type": "markdown",
   "id": "78a92ceca9fa4119",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the best classifier model from its checkpoint with the hyperparameters of its run",
   "id": "ddbc777af0e0d97e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "classifier_model = CqaModule.load_from_checkpoint(checkpoint_path, model=Classifier(hidden_dim=512, dropout=0.2), loss_function=nn.CrossEntropyLoss)",
   "id": "f52a88e45f63b520"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run evaluation on the test set and save the predictions, the logits of each prediction and the true labels",
   "id": "67fb5e03ea748e65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_model(model, dataloader) -> tuple[np.array, np.array, np.array]:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    predictions, logits, true_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            l = model(inputs)\n",
    "            l = l.to(\"cpu\")\n",
    "            preds = torch.argmax(l, dim=-1)\n",
    "            \n",
    "            logits.extend(l.numpy())\n",
    "            predictions.extend(preds.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(logits), np.array(true_labels)"
   ],
   "id": "929d77f442aedfec"
  },
  {
   "cell_type": "code",
   "id": "ad2e3b7113c7941a",
   "metadata": {},
   "source": "predictions, logits, labels = evaluate_model(classifier_model, test_loader_classifier)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Accuracy on test set",
   "id": "89b512a5dc2fa17f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "acc = torchmetrics.Accuracy(\"multiclass\", num_classes=5)\n",
    "acc.update(predictions, labels)\n",
    "print(f\"Test Accuracy: {acc.compute():.2%}\")"
   ],
   "id": "6839fd37dfbe2fe1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create Confusion Matrix",
   "id": "48754eda8babdbdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cm = torchmetrics.ConfusionMatrix(\"multiclass\", num_classes=5)\n",
    "cm.update(predictions, labels)\n",
    "fig, ax = cm.plot(labels=[\"A\", \"B\", \"C\", \"D\", \"E\"], cmap=\"plasma\")\n",
    "cbar = fig.colorbar(ax.images[0], ax=ax)\n",
    "plt.show()"
   ],
   "id": "116461c0d3da2456"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Result description\n",
    "\n",
    "#TODO: describe results (objectively)"
   ],
   "id": "a2fd2533359faad6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Error analysis\n",
    "#TODO: implement code for error analysis"
   ],
   "id": "b38e23b3a0bc47ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "misclassified_indices = np.where(predictions != labels)[0]\n",
    "\n",
    "error_collection = []\n",
    "for index in misclassified_indices:\n",
    "    probs = nn.functional.softmax(torch.tensor(logits[index]), dim=-1)\n",
    "    top3_indices = np.argsort(probs)[::-1][:3]\n",
    "    top3_probs = probs[top3_indices]\n",
    "    \n",
    "    error_collection.append({\n",
    "        \"Index\": index,\n",
    "        \"True Label\": labels[index],\n",
    "        \"Predicted Label\": predictions[index],\n",
    "        \"Confidence\": probs[predictions[index]],\n",
    "        \"Top-1 Class\": top3_indices[0],\n",
    "        \"Top-1 Prob\": top3_probs[0],\n",
    "        \"Top-2 Class\": top3_indices[1],\n",
    "        \"Top-2 Prob\": top3_probs[1],\n",
    "        \"Top-3 Class\": top3_indices[2],\n",
    "        \"Top-3 Prob\": top3_probs[2],\n",
    "    })\n",
    "\n",
    "df_errors = pd.DataFrame(error_collection)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "df_errors.head(10)"
   ],
   "id": "861bafaff7eacb27"
  },
  {
   "cell_type": "markdown",
   "id": "3bb349b7a3afb091",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c163ba3cc6c0116d",
   "metadata": {},
   "outputs": [],
   "source": "#TODO: interpret results"
  },
  {
   "cell_type": "markdown",
   "id": "670529384ff1a832",
   "metadata": {},
   "source": [
    "# 2. Architecture: RNN+Classifier\n",
    "## WordEmbeddings &rarr; RNN &rarr; Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdcb2c089c31f7d",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "#### Network architecture (layers, dims, nonlinearities, regularizations, normalizations, classifier)\n",
    "\n",
    "* **Layers**\n",
    "    * Two GRU layers and two linear layers. Reason:\n",
    "        * Required in assignment\n",
    "        * GRU chosen over LSTM because they have similar performance, but GRU has less trainable weights, which makes model smaller\n",
    "    \n",
    "* **Dimensions**\n",
    "    * First GRU Layer: `input_dim = 300`. Reason:\n",
    "        * This must match the size of the embedding vectors\n",
    "    * Second GRU Layer: `input_dim = 32`. Reason:\n",
    "        *  This was determined to be the best hidden dimension for the GRU using hyperparameter sweeps\n",
    "    * First layer: `input_dim = 160`, `output_dim = 4096`. Reason:\n",
    "        * Hyperparameter sweeps showed the GRU model should not bidirectional\n",
    "        * Input dim is given by the size of the concatenation of the five final hidden dimension vectors of the given question\n",
    "        * Output dim determined through hyperparameter sweeps\n",
    "    * Second Layer: `input_dim = 4096`, `output_dim = 5`. Reason: \n",
    "        * Input dim must match output dim of layer 1\n",
    "        * Output dim given from problem to be solved with 5 classes\n",
    "                \n",
    "* **Nonlinearities**\n",
    "    * RELU-nonlinearity in between the two layers. Reason:\n",
    "        * Required in assignment\n",
    "\n",
    "* **Regularizations**\n",
    "    * Dropout with probability of `p = 0.02` after output activation of first layer. Reason:\n",
    "        * Ensure some information redundancy in hidden layer of classifier\n",
    "        * Best probability determined in hyperparameter sweeps\n",
    " \n",
    "* **Normalizations**\n",
    "    * No normalization was used. Reason:\n",
    "        * Not required to be used\n",
    "        * Extra computation of normalization was deemed not to be worth it\n",
    "\n",
    "* **Classifier**\n",
    "    * A multiclass classifier was used. Reason:\n",
    "        * The task is inherently a multiclass classification task with 5 classes\n",
    "        * The model was expected to perform better having to choose one class given the information of all classes at once instead of binary classification with only information of the question and one answer at a time.\n",
    "        * Comparability to classifier architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c2bae4a45e8fc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(Classifier):\n",
    "    def __init__(\n",
    "            self, \n",
    "            input_dim: int = 300, \n",
    "            hidden_dim_gru: int = 512,\n",
    "            hidden_dim_linear: int = 4096, \n",
    "            output_dim: int = 5, \n",
    "            bidirectional: bool = False,\n",
    "            num_gru_layers: int = 2,\n",
    "            dropout: float = 0.0,\n",
    "    ):\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        self.num_gru_layers = num_gru_layers\n",
    "        self.output_dim = output_dim\n",
    "        super().__init__(\n",
    "            input_dim=hidden_dim_gru * self.num_directions * self.output_dim, \n",
    "            hidden_dim=hidden_dim_linear, \n",
    "            output_dim=output_dim,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim_gru, num_layers=2, batch_first=True, bidirectional=bidirectional)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
    "        batch_size, num_choices, seq_len, emb_dim = x.shape\n",
    "        x = x.view(batch_size * num_choices, seq_len, emb_dim)\n",
    "        lengths = lengths.to(\"cpu\").type(torch.int64)\n",
    "        packed_x = nn.utils.rnn.pack_padded_sequence(x, lengths.repeat_interleave(num_choices), batch_first=True)\n",
    "        \n",
    "        h0 = torch.zeros(self.num_gru_layers * self.num_directions, batch_size * num_choices, self.gru.hidden_size).to(x.device)\n",
    "\n",
    "        _, hn = self.gru(packed_x, h0)\n",
    "        fnn_in = hn[-self.num_directions:, :, :].transpose(0, 1).flatten(-2, -1).view(batch_size, -1)\n",
    "\n",
    "        return super().forward(fnn_in)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        self.gru.reset_parameters()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23810130acebbab",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "#### Loss, optimizer\n",
    "* **Loss function**: CrossEntropyLoss. Reason:\n",
    "    * Architecture is designed as a multiclass classifier\n",
    "\n",
    "* **Optimizer**: AdamW. Reason:\n",
    "    * Good experience with AdamW in past projects\n",
    "    * Adaptive learning rates based on gradients\n",
    "\n",
    "#### Experiment design (model/optimizer/loss variants, hyperparameters)\n",
    "\n",
    "* **Model/Optimizer/Loss variants**: Two model architectures were tried:\n",
    "    * Architecture 1: Concatenation of all answer embedding to the question separated by separator embeddings. Reason:\n",
    "        * Very easy to implement\n",
    "        * Seemed like a sensible way to tackle the problem\n",
    "    * Architecture 2 (final): Each answer embedding separately concatenated to question embeddings with separator embedding inbetween. Reason:\n",
    "        * Bad performance of first model architecture\n",
    "        * Every final hidden state has same amount of time steps encoded\n",
    "    * Optimizer and loss were not varied. Reason: \n",
    "        * CrossEntropyLoss is only meaningful loss function for this problem\n",
    "        * AdamW optimizer was deemed to be superior (in hindsight most likely a false assumption)\n",
    "\n",
    "* **Hyperparameters**: The following parameters were chosen for the baseline model\n",
    "    * learning rate: 1e-4\n",
    "    * hidden dimension classifier: 2048\n",
    "    * hidden dimension gru: 128\n",
    "    * bidirectional: False\n",
    "    * training epochs: 100\n",
    "    * adam epsilon: 1e-8\n",
    "    * dropout: 0.1\n",
    "    * weight decay: 0.0\n",
    "    * scheduler start percentage: 0.1\n",
    "    * **Goal**: Maximize validation accuracy\n",
    "    * Reason:\n",
    "        * Baseline hyperparameters were chosen based on experience and sensibility\n",
    "        * Maximizing validation accuracy was chosen because as many questions as possible should be answered correctly, no matter how wrong the others are\n",
    "\n",
    "#### Number of training runs\n",
    "\n",
    "* 1 run on baseline model. Reason:\n",
    "    * Have comparable result on hyperparameters that were deemed good at implementation time\n",
    "* 50 runs in first broad sweep. Reason:\n",
    "    * 50 runs to cover a large enough range of the hyperparameter combinations\n",
    "    * Broad range of values for most hyperparameters to determine which values are promising\n",
    "    * Sweep using *Bayes* method to automatically tune in on promising parameter combinations\n",
    "* 50 runs in second narrow sweep. Reason:\n",
    "    * 50 runs because still a lot of possible hyperparameter combinations\n",
    "    * Further show the importance and impact of narrower ranges of hyperparameters\n",
    "    * Use narrow band of values in ranges deemed promising in first hyperparameter sweep\n",
    "* 50 runs in last extra sweep. Reason:\n",
    "    * Models with highest validation accuracy in second sweep were strongly overfitting and only reaching high validation accuracy for one epoch\n",
    "    * Choose hyperparameter ranges of model in second sweep that looks like it has some generalization capacity\n",
    "    * Adjust hyperparameter ranges to values that were shown not to be too prone to overfitting in past two sweeps\n",
    "\n",
    "#### Model checkpointing\n",
    "\n",
    "* Best and last epoch for every run is checkpointed. Reason:\n",
    "    * Keep best run for possible later test set evaluation\n",
    "    * Keep last run for possible later elongated training or fine-tuning\n",
    "\n",
    "#### Early stopping\n",
    "\n",
    "* Early stopping after 30 epochs of no improvement on validation accuracy. Reason:\n",
    "    * Do not waste computation\n",
    "    * Model accuracy was seen to further deteriorate after more than 30 epochs of no improvement\n",
    "\n",
    "#### Sweeps\n",
    "\n",
    "* Three sweeps, one broad sweep and one narrow sweep and one extra sweep. Reason:\n",
    "    * Determined to be the most efficient method of hyperparameter optimization\n",
    "    * *Bayes* sweep method is good tradeoff of computation efficiency and testing for of full range of parameters"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Training routine\n",
    "\n",
    "Define the function **train_rnn_plus_classifier** which describes the training routine for the classifier model using the **Trainer** class of *lightning* "
   ],
   "id": "ad9ae8c92f875001"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a870444a893c16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_plus_classifier(config, logger, *callbacks):\n",
    "    L.seed_everything(42)\n",
    "    model = CqaModule(\n",
    "        RNNClassifier(\n",
    "            hidden_dim_gru=config.get(\"hd_gru\"),\n",
    "            hidden_dim_linear=config.get(\"hd_cls\"),\n",
    "            bidirectional=config.get(\"bidirectional\"),\n",
    "            dropout=config.get(\"drp\"),\n",
    "        ),\n",
    "        nn.CrossEntropyLoss,\n",
    "        **config\n",
    "    )\n",
    "    trainer = L.Trainer(\n",
    "        max_epochs=config.get(\"epochs\"),\n",
    "        accelerator=\"auto\",\n",
    "        devices=1,\n",
    "        callbacks=list(callbacks),\n",
    "        logger=logger,\n",
    "    )\n",
    "    trainer.fit(model, train_loader_rnn, valid_loader_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441eee485b252e03",
   "metadata": {},
   "source": [
    "Define run parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "41e467b32185e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"RNN+Classifier_Baseline\"\n",
    "config = dict(\n",
    "    lr=1e-4,\n",
    "    hd_cls=2048,\n",
    "    hd_gru=128,\n",
    "    bidirectional=False,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=len(train_loader_rnn),\n",
    "    adam_e=1e-8,\n",
    "    drp=0.1,\n",
    "    wd=0.0,\n",
    "    pct_start=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce958849464f1f",
   "metadata": {},
   "source": "#### Checkpointing"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "30798af57774703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"./lightning_checkpoints\",\n",
    "    filename=get_run_name(MODEL_NAME, config) + \"-{epoch:02d}-{valid_acc:.2f}\",\n",
    "    monitor=\"valid_acc\",\n",
    "    save_last=True,\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0e84624145fb1",
   "metadata": {},
   "source": "#### Early stopping"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "34553d9464e6aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = L.pytorch.callbacks.EarlyStopping(\n",
    "    monitor=\"valid_acc\",\n",
    "    patience=30,\n",
    "    mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518191c47d06b261",
   "metadata": {},
   "source": [
    "Initialize wandb experiment tracking for run\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "12d4fb483b7a6f82",
   "metadata": {},
   "source": [
    "with wandb.init(\n",
    "    entity=\"david-schurtenberger\",\n",
    "    project=\"NLP_Project_1\",\n",
    "    name=get_run_name(MODEL_NAME, config),\n",
    "    config=config,\n",
    ") as run:\n",
    "    wandb_logger = WandbLogger(project=\"NLP_Project_1\")\n",
    "    train_rnn_plus_classifier(run.config, wandb_logger, checkpoint_callback, early_stopping_callback)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e9fbbaa9081e158f",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "91b8bb5ef59a9f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"RNN+Classifier\"\n",
    "def rnn_sweep(config=None):\n",
    "    with wandb.init(config=config) as run:\n",
    "        config = wandb.config\n",
    "        run.name = get_run_name(MODEL_NAME, config)\n",
    "        checkpoint_callback = L.pytorch.callbacks.ModelCheckpoint(\n",
    "            dirpath=\"./lightning_checkpoints\",\n",
    "            filename=get_run_name(MODEL_NAME, config) + \"-{epoch:02d}-{valid_acc:.2f}\",\n",
    "            monitor=\"valid_acc\",\n",
    "            save_last=True,\n",
    "            mode=\"max\"\n",
    "        )\n",
    "        early_stopping_callback = L.pytorch.callbacks.EarlyStopping(\n",
    "            monitor=\"valid_acc\",\n",
    "            patience=30,\n",
    "            mode=\"max\"\n",
    "        )\n",
    "        wandb_logger = WandbLogger(log_model=True)\n",
    "        train_rnn_plus_classifier(config, wandb_logger, checkpoint_callback, early_stopping_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e2f40f4a5c674d",
   "metadata": {},
   "source": [
    "Broad sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6b0d6fbbd5c4732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_sweep_parameters = {\n",
    "        \"lr\": {\"values\": [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]},\n",
    "        \"hd_cls\": {\"values\": [512, 1024, 2048, 4096, 8192]},\n",
    "        \"hd_gru\": {\"values\": [64, 128, 256, 512]},\n",
    "        \"bidirectional\": {\"values\": [True, False]},\n",
    "        \"wd\": {\"min\": 0.0, \"max\": 1e-3},\n",
    "        \"adam_e\": {\"value\": 1e-8},\n",
    "        \"drp\": {\"min\": 0.0, \"max\": 0.3},\n",
    "        \"pct_start\": {\"values\": [0.1, 0.2, 0.3]},\n",
    "        \"epochs\": {\"value\": 100},\n",
    "        \"steps_per_epoch\": {\"value\": len(train_loader_rnn)},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d9a80d2df08ff481",
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_sweep_parameters = {\n",
    "        \"lr\": {\"values\": [3e-4, 1e-3, 3e-3, 1e-2]}, # equivalent to [1e-3, 1e-2.5, 1e-2]\n",
    "        \"hd_cls\": {\"values\": [512, 1024, 2048, 4096, 8192]},\n",
    "        \"hd_gru\": {\"values\": [32, 64, 128, 256, 512, 1024]},\n",
    "        \"bidirectional\": {\"value\": False},\n",
    "        \"wd\": {\"values\": [1e-5, 1e-4, 1e-3]},\n",
    "        \"adam_e\": {\"values\": [1e-7, 1e-8, 1e-9]},\n",
    "        \"drp\": {\"values\": [0, 0.01, 0.02, 0.03]},\n",
    "        \"pct_start\": {\"value\": 0.3},\n",
    "        \"epochs\": {\"value\": 200},\n",
    "        \"steps_per_epoch\": {\"value\": len(train_loader_rnn)},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e9f01a4b1130a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"RNN+ClassifierSweep_Narrow\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"max_valid_acc\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": narrow_sweep_parameters,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "37fa4e9fb61f669f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: icgxcgbp\n",
      "Sweep URL: https://wandb.ai/david-schurtenberger/NLP_Project_1/sweeps/icgxcgbp\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(\n",
    "    sweep=sweep_config, \n",
    "    entity=\"david-schurtenberger\",\n",
    "    project=\"NLP_Project_1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "id": "c7b91b503c2f6a46",
   "metadata": {},
   "source": [
    "wandb.agent(sweep_id=sweep_id, function=rnn_sweep, count=50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e75023d439fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.api.stop_sweep(sweep_id)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Choose best model from hyperparameter sweeps and load checkpoint at peak validation accuracy",
   "id": "ddd841edc36fab1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "checkpoint_path = \"lightning_checkpoints/RNN+Classifier_adam_e=0.00000_bidirectional=False_drp=0.02000_epochs=200_hd_cls=4096_hd_gru=32_lr=0.01000_pct_start=0.30000_steps_per_epoch=18_wd=0.00010_250401105648-epoch=168-val_acc=0.00.ckpt\"",
   "id": "6749a74e022e7b20"
  },
  {
   "cell_type": "markdown",
   "id": "ce68cd63697752b0",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the best classifier model from its checkpoint with the hyperparameters of its run",
   "id": "ac82c91c56a79946"
  },
  {
   "cell_type": "code",
   "id": "b414718dbed6bd16",
   "metadata": {},
   "source": "rnn_model = CqaModule.load_from_checkpoint(checkpoint_path, model=RNNClassifier(hidden_dim_gru=32, hidden_dim_linear=4096, dropout=0.02), loss_function=nn.CrossEntropyLoss)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run evaluation on the test set and save the predictions, the logits of each prediction and the true labels",
   "id": "cded9b45638f5828"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_model(model, dataloader) -> tuple[np.array, np.array, np.array]:\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.eval()\n",
    "    predictions, logits, true_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, lengths, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "            l = model(inputs, lengths)\n",
    "            l = l.to(\"cpu\")\n",
    "            preds = torch.argmax(l, dim=-1)\n",
    "\n",
    "            logits.extend(l.numpy())\n",
    "            predictions.extend(preds.numpy())\n",
    "            true_labels.extend(labels.numpy())\n",
    "\n",
    "    return np.array(predictions), np.array(logits), np.array(true_labels)"
   ],
   "id": "1586737a49613922"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "predictions, logits, labels = evaluate_model(rnn_model, test_loader_rnn)",
   "id": "c4edae7d6b05b1ad"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Accuracy on test set",
   "id": "d2282658ad65fe3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "acc = torchmetrics.Accuracy(\"multiclass\", num_classes=5)\n",
    "acc.update(predictions, labels)\n",
    "print(f\"Test Accuracy: {acc.compute():.2%}\")"
   ],
   "id": "a0b7a56f9dd3f878"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Confusion Matrix",
   "id": "7d709677ea36b82a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cm = torchmetrics.ConfusionMatrix(\"multiclass\", num_classes=5)\n",
    "cm.update(predictions, labels)\n",
    "fig, ax = cm.plot(labels=[\"A\", \"B\", \"C\", \"D\", \"E\"], cmap=\"plasma\")\n",
    "cbar = fig.colorbar(ax.images[0], ax=ax)\n",
    "plt.show()"
   ],
   "id": "b1395c3db24ab63d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Result description\n",
    "\n",
    "#TODO: describe results (objectively)"
   ],
   "id": "bb08c89624f4839c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Error analysis",
   "id": "86d255fd4aff1a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "misclassified_indices = np.where(predictions != labels)[0]\n",
    "\n",
    "error_collection = []\n",
    "for index in misclassified_indices:\n",
    "    probs = nn.functional.softmax(torch.tensor(logits[index]), dim=-1)\n",
    "    top3_indices = np.argsort(probs)[::-1][:3]\n",
    "    top3_probs = probs[top3_indices]\n",
    "    \n",
    "    error_collection.append({\n",
    "        \"Index\": index,\n",
    "        \"True Label\": labels[index],\n",
    "        \"Predicted Label\": predictions[index],\n",
    "        \"Confidence\": probs[predictions[index]],\n",
    "        \"Top-1 Class\": top3_indices[0],\n",
    "        \"Top-1 Prob\": top3_probs[0],\n",
    "        \"Top-2 Class\": top3_indices[1],\n",
    "        \"Top-2 Prob\": top3_probs[1],\n",
    "        \"Top-3 Class\": top3_indices[2],\n",
    "        \"Top-3 Prob\": top3_probs[2],\n",
    "    })\n",
    "\n",
    "df_errors = pd.DataFrame(error_collection)\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "df_errors.head(10)"
   ],
   "id": "624ce0481b2e17b2"
  },
  {
   "cell_type": "markdown",
   "id": "f241fe1cf1168f92",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd1ce96fabd34a",
   "metadata": {},
   "outputs": [],
   "source": "#TODO: interpret results"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
