{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20bae9b5",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory\n",
    "In this exercise, we will implement an LSTM. In the class, we have already seen the definition of the LSTM update rules at time step $t$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f_t &= \\sigma(W_f h_{t-1} + U_f x_t + b_f) \\\\\n",
    "i_t &= \\sigma(W_i h_{t-1} + U_i x_t + b_i) \\\\\n",
    "o_t &= \\sigma(W_o h_{t-1} + U_o x_t + b_o) \\\\\n",
    "\\tilde{c}_t &= \\tanh(W_c h_{t-1} + U_c x_t + b_c) \\\\\n",
    "c_t &= f_t * c_{t-1} + i_t * \\tilde{c}_t \\\\\n",
    "h_t &= o_t * \\tanh(c_t)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "e7619e77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:11:04.149012Z",
     "start_time": "2025-03-13T09:10:59.780985Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "c18fa802",
   "metadata": {},
   "source": [
    "Implement this original version of the LSTM as an `LSTMCell`."
   ]
  },
  {
   "cell_type": "code",
   "id": "5b7cf7f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:44:47.741157Z",
     "start_time": "2025-03-13T09:44:47.728259Z"
    }
   },
   "source": [
    "class LSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        # hidden_state weights\n",
    "        self.Wf = nn.Parameter(torch.zeros(hidden_dim, hidden_dim))\n",
    "        self.Wi = nn.Parameter(torch.zeros(hidden_dim, hidden_dim))\n",
    "        self.Wo = nn.Parameter(torch.zeros(hidden_dim, hidden_dim))\n",
    "        self.Wc = nn.Parameter(torch.zeros(hidden_dim, hidden_dim))\n",
    "        \n",
    "        # input weights\n",
    "        self.Uf = nn.Parameter(torch.zeros(hidden_dim, input_dim))\n",
    "        self.Ui = nn.Parameter(torch.zeros(hidden_dim, input_dim))\n",
    "        self.Uo = nn.Parameter(torch.zeros(hidden_dim, input_dim))\n",
    "        self.Uc = nn.Parameter(torch.zeros(hidden_dim, input_dim))\n",
    "        \n",
    "        # bias\n",
    "        self.bf = nn.Parameter(torch.zeros(hidden_dim))\n",
    "        self.bi = nn.Parameter(torch.zeros(hidden_dim))  \n",
    "        self.bo = nn.Parameter(torch.zeros(hidden_dim))  \n",
    "        self.bc = nn.Parameter(torch.zeros(hidden_dim))  \n",
    "        \n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        ft = torch.sigmoid(self.Wf @ hidden_state + self.Uf @ x + self.bf)\n",
    "        it = torch.sigmoid(self.Wi @ hidden_state + self.Ui @ x + self.bi)\n",
    "        ot = torch.sigmoid(self.Wo @ hidden_state + self.Uo @ x + self.bo)\n",
    "        c_t = torch.tanh(self.Wc @ hidden_state + self.Uc @ x + self.bc)\n",
    "        ct = ft * cell_state + it * c_t\n",
    "        ht = ot * torch.tanh(ct)\n",
    "        return ht, ct\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            nn.init.uniform_(weight, -1, 1)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "f49ac90b",
   "metadata": {},
   "source": [
    "Create a 2-layer LSTM from your LSTMCell base class and run a forward pass with a random input sequence to test that all your dimensions are correct."
   ]
  },
  {
   "cell_type": "code",
   "id": "1562d0bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:44:49.513713Z",
     "start_time": "2025-03-13T09:44:49.505935Z"
    }
   },
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.l1 = LSTMCell(input_dim, hidden_dim)\n",
    "        self.l2 = LSTMCell(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x, h1, c1, h2, c2):\n",
    "        h1, c1 = self.l1(x, h1, c1)\n",
    "        h2, c2 = self.l2(h1, h2, c2)\n",
    "        return h1, c1, h2, c2\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        for weight in self.parameters():\n",
    "            nn.init.uniform_(weight, -1, 1)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:44:50.279048Z",
     "start_time": "2025-03-13T09:44:50.265362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_dim = 10\n",
    "hidden_dim = 20\n",
    "seq_length = 5\n",
    "\n",
    "lstm = LSTM(input_dim, hidden_dim)\n",
    "lstm.reset_parameters()\n",
    "h1 = torch.randn(hidden_dim)\n",
    "h2 = torch.randn(hidden_dim)\n",
    "c1 = torch.randn(hidden_dim)\n",
    "c2 = torch.randn(hidden_dim)\n",
    "x = torch.randn(seq_length, input_dim)\n",
    "\n",
    "result_hidden = []\n",
    "result_cell = []\n",
    "\n",
    "for i in range(seq_length):\n",
    "    h1, c1, h2, c2 = lstm(x[i], h1, c1, h2, c2)\n",
    "    result_hidden.append((h1, h2))\n",
    "    result_cell.append((c1, c2))\n",
    "    \n",
    "print(len(result_hidden))\n",
    "print(result_hidden[0][0].shape)\n",
    "print(len(result_cell))\n",
    "print(result_cell[0][0].shape)\n",
    "    "
   ],
   "id": "a4d4667240e72283",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "torch.Size([20])\n",
      "5\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "dbc4028e",
   "metadata": {},
   "source": [
    "Implement a subclass of your LSTM that uses a coupled forget and input gate, i.e. the cell state update becomes:\n",
    "\n",
    "$$c_t = f_t * c_{t-1} + (1-f_t) * \\tilde{c}_t$$"
   ]
  },
  {
   "cell_type": "code",
   "id": "821ee42c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:48:35.344654Z",
     "start_time": "2025-03-13T09:48:35.329716Z"
    }
   },
   "source": [
    "class CoupledLSTMCell(LSTMCell):\n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        ft = torch.sigmoid(self.Wf @ hidden_state + self.Uf @ x + self.bf)\n",
    "        ot = torch.sigmoid(self.Wo @ hidden_state + self.Uo @ x + self.bo)\n",
    "        c_t = torch.tanh(self.Wc @ hidden_state + self.Uc @ x + self.bc)\n",
    "        ct = ft * cell_state + (1 - ft) * c_t\n",
    "        ht = ot * torch.tanh(ct)\n",
    "        return ht, ct\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:48:36.489570Z",
     "start_time": "2025-03-13T09:48:36.475672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CoupledLSTM(LSTM):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = CoupledLSTMCell(input_dim, hidden_dim)\n",
    "        self.l2 = CoupledLSTMCell(hidden_dim, hidden_dim)\n",
    "    "
   ],
   "id": "22acda6126b85e43",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:48:56.174395Z",
     "start_time": "2025-03-13T09:48:56.153306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lstm = CoupledLSTM(input_dim, hidden_dim)\n",
    "lstm.reset_parameters()\n",
    "h1 = torch.randn(hidden_dim)\n",
    "h2 = torch.randn(hidden_dim)\n",
    "c1 = torch.randn(hidden_dim)\n",
    "c2 = torch.randn(hidden_dim)\n",
    "x = torch.randn(seq_length, input_dim)\n",
    "\n",
    "result_hidden = []\n",
    "result_cell = []\n",
    "\n",
    "for i in range(seq_length):\n",
    "    h1, c1, h2, c2 = lstm(x[i], h1, c1, h2, c2)\n",
    "    result_hidden.append((h1, h2))\n",
    "    result_cell.append((c1, c2))\n",
    "    \n",
    "print(len(result_hidden))\n",
    "print(result_hidden[0][0].shape)\n",
    "print(len(result_cell))\n",
    "print(result_cell[0][0].shape)"
   ],
   "id": "65861174507b4a43",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "torch.Size([20])\n",
      "5\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "371c955b",
   "metadata": {},
   "source": [
    "**Bonus:** Implement *peephole connections* as described at the start of the Section *Variants on Long Short Term Memory* in [this blog post explaining LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n",
    "\n",
    "The gate update definitions get an additional term that looks at the cell state:\n",
    "$$\n",
    "\\begin{align}\n",
    "f_t &= \\sigma(W_f h_{t-1} + U_f x_t + b_f \\boldsymbol{+ V_f c_{t-1}}) \\\\\n",
    "i_t &= \\sigma(W_i h_{t-1} + U_i x_t + b_i \\boldsymbol{+ V_i c_{t-1}}) \\\\\n",
    "o_t &= \\sigma(W_o h_{t-1} + U_o x_t + b_o \\boldsymbol{+ V_o c_t})\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "To make the task a bit easier, we will implement the last equation with the cell state of the previous time step $t-1$ as $$o_t = \\sigma(W_o h_{t-1} + U_o x_t + b_o \\boldsymbol{+ V_o c_{t-1}})$$ instead."
   ]
  },
  {
   "cell_type": "code",
   "id": "97f33705",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:52:56.354540Z",
     "start_time": "2025-03-13T09:52:56.343468Z"
    }
   },
   "source": [
    "class PeepholeLSTMCell(LSTMCell):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__(input_dim, hidden_dim)\n",
    "        # cell_state weights\n",
    "        self.Vf = nn.Parameter(torch.zeros(hidden_dim, hidden_dim))\n",
    "        self.Vi = nn.Parameter(torch.zeros(hidden_dim, hidden_dim))\n",
    "        self.Vo = nn.Parameter(torch.zeros(hidden_dim, hidden_dim))\n",
    "        \n",
    "    def forward(self, x, hidden_state, cell_state):\n",
    "        ft = torch.sigmoid(self.Wf @ hidden_state + self.Uf @ x + self.bf + self.Vf @ cell_state)\n",
    "        it = torch.sigmoid(self.Wi @ hidden_state + self.Ui @ x + self.bi + self.Vi @ cell_state)\n",
    "        c_t = torch.tanh(self.Wc @ hidden_state + self.Uc @ x + self.bc)\n",
    "        ct = ft * cell_state + it * c_t\n",
    "        ot = torch.sigmoid(self.Wo @ hidden_state + self.Uo @ x + self.bo + self.Vo @ cell_state)\n",
    "        ht = ot * torch.tanh(ct)\n",
    "        return ht, ct"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:53:23.882035Z",
     "start_time": "2025-03-13T09:53:23.876855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PeepholeLSTM(LSTM):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        nn.Module.__init__(self)\n",
    "        self.l1 = PeepholeLSTMCell(input_dim, hidden_dim)\n",
    "        self.l2 = PeepholeLSTMCell(hidden_dim, hidden_dim)"
   ],
   "id": "d93441b578aa3ecb",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T09:53:42.322440Z",
     "start_time": "2025-03-13T09:53:42.302988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lstm = PeepholeLSTM(input_dim, hidden_dim)\n",
    "lstm.reset_parameters()\n",
    "h1 = torch.randn(hidden_dim)\n",
    "h2 = torch.randn(hidden_dim)\n",
    "c1 = torch.randn(hidden_dim)\n",
    "c2 = torch.randn(hidden_dim)\n",
    "x = torch.randn(seq_length, input_dim)\n",
    "\n",
    "result_hidden = []\n",
    "result_cell = []\n",
    "\n",
    "for i in range(seq_length):\n",
    "    h1, c1, h2, c2 = lstm(x[i], h1, c1, h2, c2)\n",
    "    result_hidden.append((h1, h2))\n",
    "    result_cell.append((c1, c2))\n",
    "    \n",
    "print(len(result_hidden))\n",
    "print(result_hidden[0][0].shape)\n",
    "print(len(result_cell))\n",
    "print(result_cell[0][0].shape)"
   ],
   "id": "5579366922c36184",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "torch.Size([20])\n",
      "5\n",
      "torch.Size([20])\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
