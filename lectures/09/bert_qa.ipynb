{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d06a0aa5",
   "metadata": {},
   "source": [
    "# Question Answering with BERT\n",
    "In this exercise, we will use a pretrained BERT model, finetuned on question answering, to identify the answer to a question in a paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86be112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q torch\n",
    "%pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66b8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e311c68d",
   "metadata": {},
   "source": [
    "## Knowledge distillation\n",
    "\n",
    "[Knowledge distillation](https://en.wikipedia.org/wiki/Knowledge_distillation) is a practice in deep learning to train a much smaller *student* model on the outputs of a large *teacher* model. In that way, one can reduce model parameters a lot while performance decreases only by a little.\n",
    "\n",
    "We will use a distilled model: `distilbert-base-uncased-distilled-squad`. From the 5 parts of the name, we know that:\n",
    "- it is a distilled version of the BERT model\n",
    "- it used BERT-base as a teacher model\n",
    "- it is uncased, so converts all inputs into lowercase\n",
    "- it was distilled again during finetuning (normally it's only done once from the pretrained model)\n",
    "- the model was finetuned on squad (v1.1), a question answering dataset\n",
    "\n",
    "We will now download and initialize the model. Read the [model documentation](https://huggingface.co/distilbert-base-uncased-distilled-squad) on HuggingFace's model hub to see how it is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "model = DistilBertForQuestionAnswering.from_pretrained('distilbert-base-uncased-distilled-squad')\n",
    "model.eval()\n",
    "pass  # Suppress output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d14ff7",
   "metadata": {},
   "source": [
    "## Extractive Question Answering\n",
    "\n",
    "For extractive question answering, we are given a paragraph and a question, and have to find the answer to the question in the paragraph. Look at the paragraphs (starts of Wikipedia articles about New York City, the capybara, and american football) and questions that we will use for this exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e12679",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs = [\n",
    "    \"New York, often called New York City (NYC), is the most populous city in the United States. With a 2020 population of 8,804,190 distributed over 300.46 square miles (778.2 km2), New York City is also the most densely populated major city in the United States. Located at the southern tip of New York State, the city is based in the Eastern Time Zone and constitutes the geographical and demographic center of both the Northeast megalopolis and the New York metropolitan area, the largest metropolitan area in the world by urban landmass. With over 20.1 million people in its metropolitan statistical area and 23.5 million in its combined statistical area as of 2020, New York is one of the world's most populous megacities. New York City is a global cultural, financial, and media center with a significant influence on commerce, health care and life sciences, entertainment, research, technology, education, politics, tourism, dining, art, fashion, and sports. New York is the most photographed city in the world. Home to the headquarters of the United Nations, New York is an important center for international diplomacy, an established safe haven for global investors, and is sometimes described as the capital of the world.\",\n",
    "    \"The capybara or greater capybara (Hydrochoerus hydrochaeris) is a giant cavy rodent native to South America. It is the largest living rodent and a member of the genus Hydrochoerus. The only other extant member is the lesser capybara (Hydrochoerus isthmius). Its close relatives include guinea pigs and rock cavies, and it is more distantly related to the agouti, the chinchilla, and the nutria. The capybara inhabits savannas and dense forests and lives near bodies of water. It is a highly social species and can be found in groups as large as 100 individuals, but usually lives in groups of 10â€“20 individuals. The capybara is hunted for its meat and hide and also for grease from its thick fatty skin. It is not considered a threatened species.\",\n",
    "    \"American football (referred to simply as football in the United States and Canada), also known as gridiron, is a team sport played by two teams of eleven players on a rectangular field with goalposts at each end. The offense, the team with possession of the oval-shaped football, attempts to advance down the field by running with the ball or passing it, while the defense, the team without possession of the ball, aims to stop the offense's advance and to take control of the ball for themselves. The offense must advance at least ten yards in four downs or plays; if they fail, they turn over the football to the defense, but if they succeed, they are given a new set of four downs to continue the drive. Points are scored primarily by advancing the ball into the opposing team's end zone for a touchdown or kicking the ball through the opponent's goalposts for a field goal. The team with the most points at the end of a game wins.\",\n",
    "]\n",
    "questions = [\n",
    "    [\n",
    "        \"What is New York's population?\",\n",
    "        \"How many people live in New York's metropolitan area?\",\n",
    "        \"To what industries is New York a center?\",\n",
    "        \"What is New York known for?\",\n",
    "        \"What is New York also called?\",\n",
    "        \"What is New York also sometimes called?\",\n",
    "        \"What is New York also sometimes described?\",\n",
    "    ],\n",
    "    [\n",
    "        \"What is the scientific name of the capybara?\",\n",
    "        \"What family of animals does the capybara belong to?\",\n",
    "        \"What are close relatives of the capybara?\",\n",
    "        \"What is the size of groups that the capybara lives in?\",\n",
    "        \"What is the capybara hunted for?\",\n",
    "    ],\n",
    "    [\n",
    "        \"Under what name is American football also known?\",\n",
    "        \"How many players are in a team?\",\n",
    "        \"By what means can the offense advance?\",\n",
    "        \"How many yards must a team advance in four downs?\",\n",
    "        \"How does a team score points?\",\n",
    "        \"How does a team win?\",\n",
    "    ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a32b0f",
   "metadata": {},
   "source": [
    "## Answering Questions\n",
    "\n",
    "For each of the paragraphs above, we will now answer the associated questions. Take a look at the [model documentation](https://huggingface.co/distilbert-base-uncased-distilled-squad). First, use HuggingFace's pipeline abstraction. Look at the outputs of your model and describe the information it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b9b740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bbea340",
   "metadata": {},
   "source": [
    "Now we will do the same by directly using the tokenizer and the model we loaded at the start. The model documentation also has an example to get you started. Look at the outputs of the model. Perform the necessary steps to give an answer like the pipeline above. Do the answers match?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924dbbf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0742687d",
   "metadata": {},
   "source": [
    "Some of the answers do not match, which tells us that pipeline's implementation does something different \n",
    "from what we did. Two things to note:\n",
    "1. A different tokenization procedure seems to have been used, as the answer to the first question appears\n",
    "without spaces in the pipeline result, and with spaces for the tokenizer + model output.\n",
    "2. The start/end indices in the pipeline model are the character start/end indices, whereas the indices we\n",
    "computed in the tokenizer + model code are the indices of the input tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d029fbcd",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Evaluation in extractive QA is done by comparing the token-level overlap between the reference answer (sometimes also called *ground truth* or *gold answer*) and the model's answer. We first compute the precision $P$ (\"how many tokens in the model's answer also appear in the reference?\") and the recall $R$ (\"how many tokens in the reference also appear in the model's answer?\"). Their harmonic mean is also called F1 score, which is our evaluation metric.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\text{P} &= \\frac{\\text{number of tokens in both answers}}{\\text{number of tokens in the model's answer}} \\\\\n",
    "\\text{R} &= \\frac{\\text{number of tokens in both answers}}{\\text{number of tokens in the reference answer}} \\\\\n",
    "\\text{F1} &= 2 \\frac{PR}{P + R} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "**Task:** Define your own solution to three of the questions above, then compute the word-level F1 score for one of the model's answers for each of them. The final result is the average over all questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f89055",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
