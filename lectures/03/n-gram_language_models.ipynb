{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c46cbd05",
   "metadata": {},
   "source": [
    "# N-Gram Language Models\n",
    "In this exercise, we will use n-gram language models to predict the probability of text, and generate it."
   ]
  },
  {
   "cell_type": "code",
   "id": "19a1c205",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:10:35.553117Z",
     "start_time": "2025-03-07T08:10:35.534106Z"
    }
   },
   "source": [
    "from multiprocessing.managers import Value\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "id": "65e74f9a",
   "metadata": {},
   "source": [
    "First, we load Jane Austen's Emma from NLTK's gutenberg corpus that we also used in a previous exercise. Tokenize and lowercase this text such that we have a list of words."
   ]
  },
  {
   "cell_type": "code",
   "id": "e8dd1c74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:10:36.734948Z",
     "start_time": "2025-03-07T08:10:35.583714Z"
    }
   },
   "source": [
    "raw_text = gutenberg.raw('austen-emma.txt')\n",
    "words = [w.lower() for w in nltk.word_tokenize(raw_text)]\n",
    "len(words)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "191855"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "60adf6a1",
   "metadata": {},
   "source": [
    "Write an n-gram language model class that takes the word list and a parameter `n` as inputs, where `n` is a positive integer larger than 1 that determines the `n` of the n-gram LM. The LM should build a dictionary of n-gram counts from the word list."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:10:36.765815Z",
     "start_time": "2025-03-07T08:10:36.759057Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(string: str) -> list[str]:\n",
    "    return [w.lower() for w in nltk.word_tokenize(string)]"
   ],
   "id": "9e8d1a6e5c655a85",
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "9635e870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:10:36.801093Z",
     "start_time": "2025-03-07T08:10:36.793304Z"
    }
   },
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class NGramLanguageModel:\n",
    "    \n",
    "    def __init__(self, words, n):\n",
    "        assert n > 1, \"n needs to be a positive integer > 1\"\n",
    "        assert n <= len(words), \"n can't be larger than the number of words\"\n",
    "        self.counts: dict[tuple[str, ...], int] = defaultdict(int)\n",
    "        self.n = n\n",
    "        for i in range(len(words) - n + 1):\n",
    "            ngram = tuple(words[i : i+n])\n",
    "            self.counts[ngram] += 1\n",
    "            self.counts[ngram[:-1]] += 1\n",
    "        self.counts[ngram[1:]] += 1"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "c6c2d523",
   "metadata": {},
   "source": [
    "Now we \"train\" the n-gram LM by building the n-gram counts of the Emma novel. Use a low `n` (i.e. 2 or 3)."
   ]
  },
  {
   "cell_type": "code",
   "id": "54b49ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:24:57.982560Z",
     "start_time": "2025-03-07T08:24:57.763780Z"
    }
   },
   "source": "lm = NGramLanguageModel(words, 3)",
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "id": "4f7bf596",
   "metadata": {},
   "source": [
    "Let's add a method `log_probability` to the n-gram LM class that computes the probability of an input string. Since multiplying many probabilities (<= 1) results in very small numbers that can underflow, we sum the log probabilities instead."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:25:00.215235Z",
     "start_time": "2025-03-07T08:25:00.208691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "def log_probability(self, input_string) -> float:\n",
    "        \"\"\" Returns the log-probability of the input string.\"\"\"\n",
    "        input_words = preprocess(input_string)\n",
    "        probability = []\n",
    "        for i in range(len(input_words) - self.n + 1):\n",
    "            ngram = tuple(input_words[i : i + self.n])\n",
    "            if ngram in self.counts:\n",
    "                probability.append(math.log(self.counts[ngram] / self.counts[ngram[:-1]]))\n",
    "        return sum(probability) / len(probability)\n",
    "\n",
    "NGramLanguageModel.log_probability = log_probability"
   ],
   "id": "502b6854d531da26",
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "id": "271e7469",
   "metadata": {},
   "source": [
    "Shorter texts will have higher log probability than longer texts, so we need to normalize it by the number of words in the input string."
   ]
  },
  {
   "cell_type": "code",
   "id": "0338f4e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:25:02.063592Z",
     "start_time": "2025-03-07T08:25:02.042344Z"
    }
   },
   "source": [
    "print(lm.log_probability(\"What is the meaning of life?\"))\n",
    "print(lm.log_probability(\"What is the meaning of life, given I am a student?\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.208105236360199\n",
      "-2.420144330727304\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "id": "398e2054",
   "metadata": {},
   "source": [
    "Lets predict the probabilities of two novels under our trained model: Jane Austen's *Sense and Sensibility* (`austen-sense.txt`) and Shakespeare's *Hamlet* (`shakespeare-hamlet.txt`).\n",
    "- What do you expect will happen?\n",
    "- What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "id": "c4dc2cce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:25:06.094448Z",
     "start_time": "2025-03-07T08:25:03.905316Z"
    }
   },
   "source": [
    "austen_sense = gutenberg.raw('austen-sense.txt')\n",
    "shakespeare_hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "print(f\"Austen Emma: {lm.log_probability(raw_text)}\")\n",
    "print(\"Austen Sense: \", lm.log_probability(austen_sense))\n",
    "print(\"Shakespeare Hamlet: \", lm.log_probability(shakespeare_hamlet))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austen Emma: -1.7492105638273363\n",
      "Austen Sense:  -2.405643228181783\n",
      "Shakespeare Hamlet:  -2.7892762868035343\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "id": "c002ddb4",
   "metadata": {},
   "source": [
    "How many n-grams are known in each input?"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:25:13.574386Z",
     "start_time": "2025-03-07T08:25:13.555364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_known_n_grams(self, input_string) -> tuple[int, int]:\n",
    "    input_words = preprocess(input_string)\n",
    "    count = 0\n",
    "    for i in range(len(input_words) - self.n + 1):\n",
    "        ngram = tuple(input_words[i : i + self.n])\n",
    "        if ngram in self.counts:\n",
    "            count += 1\n",
    "    return count, len(input_words) - self.n + 1\n",
    "\n",
    "NGramLanguageModel.count_known_n_grams = count_known_n_grams"
   ],
   "id": "4a681a8ddb36ba6",
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "id": "2adcafb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:25:16.032609Z",
     "start_time": "2025-03-07T08:25:14.143134Z"
    }
   },
   "source": [
    "known, total = lm.count_known_n_grams(raw_text)\n",
    "print(f\"Austen Emma: {known/total:.2%}, {known}/{total}\")\n",
    "known, total = lm.count_known_n_grams(austen_sense)\n",
    "print(f\"Austen Sense: {known/total:.2%}, {known}/{total}\")\n",
    "known, total = lm.count_known_n_grams(shakespeare_hamlet)\n",
    "print(f\"Shakespeare Hamlet: {known/total:.2%}, {known}/{total}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austen Emma: 100.00%, 191853/191853\n",
      "Austen Sense: 29.56%, 41806/141438\n",
      "Shakespeare Hamlet: 8.82%, 3211/36409\n"
     ]
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "id": "2be2adf0",
   "metadata": {},
   "source": [
    "Let's add a method `generate` that takes the start of a sentence (\"prompt\") and a number of words to generate, then continues our prompt."
   ]
  },
  {
   "cell_type": "code",
   "id": "9975c570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:33:35.475668Z",
     "start_time": "2025-03-07T08:33:35.457358Z"
    }
   },
   "source": [
    "import random\n",
    "\n",
    "def generate(self, prompt, num_words=10):\n",
    "    \"\"\" Continues a text starting with `prompt` for the `num_words` next words. \"\"\"\n",
    "    words = preprocess(prompt)\n",
    "    for _ in range(num_words):\n",
    "        prefix = tuple(words[-self.n + 1:])\n",
    "        if prefix not in self.counts:\n",
    "            raise ValueError(f\"Unknown n-gram (-1): {prefix}\")\n",
    "        next_word_dist = {}\n",
    "        for n_gram in self.counts:\n",
    "            if len(n_gram) == self.n and n_gram[:-1] == prefix:\n",
    "                next_word_dist[n_gram] = self.counts[n_gram] / self.counts[prefix]\n",
    "        #print(prefix, next_word_dist)\n",
    "        best_ngram, prob = max(next_word_dist.items(), key=lambda x: x[1])\n",
    "        print(best_ngram, prob)\n",
    "        words.append(best_ngram[-1])\n",
    "    return \" \".join(words)\n",
    "        \n",
    "\n",
    "NGramLanguageModel.generate = generate"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "id": "fd049682",
   "metadata": {},
   "source": [
    "Play around with a few different prompts."
   ]
  },
  {
   "cell_type": "code",
   "id": "c1d951f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:36:01.611477Z",
     "start_time": "2025-03-07T08:36:00.248098Z"
    }
   },
   "source": [
    "output = lm.generate(\"i went for a walk\", 50)\n",
    "print(output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 'walk', ',') 0.25\n",
      "('walk', ',', 'or') 0.1111111111111111\n",
      "(',', 'or', 'any') 0.07103825136612021\n",
      "('or', 'any', 'thing') 0.35294117647058826\n",
      "('any', 'thing', 'to') 0.08536585365853659\n",
      "('thing', 'to', 'be') 0.25925925925925924\n",
      "('to', 'be', 'sure') 0.04132231404958678\n",
      "('be', 'sure', ',') 0.23076923076923078\n",
      "('sure', ',', \"''\") 0.18181818181818182\n",
      "(',', \"''\", 'said') 0.3852739726027397\n",
      "(\"''\", 'said', 'he') 0.2188679245283019\n",
      "('said', 'he', ',') 0.5797101449275363\n",
      "('he', ',', '``') 0.35714285714285715\n",
      "(',', '``', 'i') 0.152\n",
      "('``', 'i', 'am') 0.16091954022988506\n",
      "('i', 'am', 'sure') 0.2715736040609137\n",
      "('am', 'sure', 'i') 0.16822429906542055\n",
      "('sure', 'i', 'should') 0.19047619047619047\n",
      "('i', 'should', 'not') 0.21100917431192662\n",
      "('should', 'not', 'have') 0.35\n",
      "('not', 'have', 'been') 0.14705882352941177\n",
      "('have', 'been', 'a') 0.07883817427385892\n",
      "('been', 'a', 'great') 0.08888888888888889\n",
      "('a', 'great', 'deal') 0.4740740740740741\n",
      "('great', 'deal', 'of') 0.40625\n",
      "('deal', 'of', 'the') 0.10256410256410256\n",
      "('of', 'the', 'two') 0.03577817531305903\n",
      "('the', 'two', ',') 0.10416666666666667\n",
      "('two', ',', 'but') 0.15384615384615385\n",
      "(',', 'but', 'i') 0.1188118811881188\n",
      "('but', 'i', 'am') 0.12987012987012986\n",
      "('i', 'am', 'sure') 0.2715736040609137\n",
      "('am', 'sure', 'i') 0.16822429906542055\n",
      "('sure', 'i', 'should') 0.19047619047619047\n",
      "('i', 'should', 'not') 0.21100917431192662\n",
      "('should', 'not', 'have') 0.35\n",
      "('not', 'have', 'been') 0.14705882352941177\n",
      "('have', 'been', 'a') 0.07883817427385892\n",
      "('been', 'a', 'great') 0.08888888888888889\n",
      "('a', 'great', 'deal') 0.4740740740740741\n",
      "('great', 'deal', 'of') 0.40625\n",
      "('deal', 'of', 'the') 0.10256410256410256\n",
      "('of', 'the', 'two') 0.03577817531305903\n",
      "('the', 'two', ',') 0.10416666666666667\n",
      "('two', ',', 'but') 0.15384615384615385\n",
      "(',', 'but', 'i') 0.1188118811881188\n",
      "('but', 'i', 'am') 0.12987012987012986\n",
      "('i', 'am', 'sure') 0.2715736040609137\n",
      "('am', 'sure', 'i') 0.16822429906542055\n",
      "('sure', 'i', 'should') 0.19047619047619047\n",
      "i went for a walk , or any thing to be sure , '' said he , `` i am sure i should not have been a great deal of the two , but i am sure i should not have been a great deal of the two , but i am sure i should\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T08:10:41.451405Z",
     "start_time": "2025-03-07T08:10:41.445665Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d95ca89d9ade5c81",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
