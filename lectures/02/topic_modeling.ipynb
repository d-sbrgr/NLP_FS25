{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53d81604-025d-4fe1-a130-6a978f5ba135",
   "metadata": {},
   "source": [
    "# Topic Modeling\n",
    "In this exercise, we will do topic modeling with gensim. Use the [topics and transformations tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html) as a reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45876ae-0f77-4bf8-8da4-b18618005327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import gensim\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e6efd1",
   "metadata": {},
   "source": [
    "For tokenizing words and stopword removal, download the NLTK punkt tokenizer and stopwords list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf524f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee84f40-20bf-47da-b0b4-a0ff28f9b5cd",
   "metadata": {},
   "source": [
    "First, we load the [Lee Background Corpus](https://hekyll.services.adelaide.edu.au/dspace/bitstream/2440/28910/1/hdl_28910.pdf) included with gensim that contains 300 news articles of the Australian Broadcasting Corporation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d72e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "train_file = datapath('lee_background.cor')\n",
    "articles_orig = open(train_file).read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b2e56f",
   "metadata": {},
   "source": [
    "Preprocess the text by lowercasing, removing stopwords, stemming, and removing rare words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a870af-9f6b-43ea-940f-558e9a21bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define stopword list\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords = stopwords | {'\\\"', '\\'', '\\'\\'', '`', '``', '\\'s'}\n",
    "\n",
    "# initialize stemmer\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def preprocess(article):\n",
    "    # tokenize\n",
    "    article = nltk.word_tokenize(article)\n",
    "\n",
    "    # lowercase all words\n",
    "    article = [word.lower() for word in article]\n",
    "\n",
    "    # remove stopwords\n",
    "    article = [word for word in article if word not in stopwords]\n",
    "\n",
    "    # optional: stem\n",
    "    article = [stemmer.stem(word) for word in article]\n",
    "    return article\n",
    "\n",
    "articles = [preprocess(article) for article in articles_orig]\n",
    "\n",
    "# create the dictionary and corpus objects that gensim uses for topic modeling\n",
    "dictionary = gensim.corpora.Dictionary(articles)\n",
    "\n",
    "# remove words that occur in less than 2 documents, or more than 50% of documents\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.5)\n",
    "temp = dictionary[0]  # load the dictionary by calling it once\n",
    "corpus_bow = [dictionary.doc2bow(article) for article in articles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ae61a",
   "metadata": {},
   "source": [
    "\n",
    "Now we create a TF-IDF model and transform the corpus into TF-IDF vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab13db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.045055071138122856), (1, 0.048886979465828866), (2, 0.09375399876622974), (3, 0.06781504448328635), (4, 0.08078452162475803), (5, 0.10134065654795091), (6, 0.058730707569876556), (7, 0.07269531841603805), (8, 0.03468336276559477), (9, 0.07660928255691886), (10, 0.06936672553118954), (11, 0.06363980541544716), (12, 0.14639572768607376), (13, 0.06561120606131572), (14, 0.05734407327660557), (15, 0.21959359152911065), (16, 0.0861673409845086), (17, 0.03352561206466457), (18, 0.05163007712346614), (19, 0.0861673409845086), (20, 0.04649508920613628), (21, 0.08078452162475803), (22, 0.058730707569876556), (23, 0.044374596135133865), (24, 0.048886979465828866), (25, 0.053711220021490196), (26, 0.04725890956009348), (27, 0.06185645660730057), (28, 0.05163007712346614), (29, 0.0861673409845086), (30, 0.056053147633726), (31, 0.06185645660730057), (32, 0.14639572768607376), (33, 0.04725890956009348), (34, 0.06022838670156517), (35, 0.06363980541544716), (36, 0.07660928255691886), (37, 0.07660928255691886), (38, 0.06185645660730057), (39, 0.13122241212263144), (40, 0.09375399876622974), (41, 0.05264172891984401), (42, 0.3350087216027434), (43, 0.06185645660730057), (44, 0.04187609020034293), (45, 0.08671983917661366), (46, 0.0861673409845086), (47, 0.04247014010577541), (48, 0.06781504448328635), (49, 0.09375399876622974), (50, 0.09375399876622974), (51, 0.1723346819690172), (52, 0.15321856511383772), (53, 0.1806851601046955), (54, 0.1331237884054016), (55, 0.06363980541544716), (56, 0.18750799753245947), (57, 0.10326015424693227), (58, 0.07660928255691886), (59, 0.07660928255691886), (60, 0.0861673409845086), (61, 0.0430836704922543), (62, 0.1356300889665727), (63, 0.07031355041807727), (64, 0.06781504448328635), (65, 0.03678793835341271), (66, 0.05163007712346614), (67, 0.044374596135133865), (68, 0.045055071138122856), (69, 0.050670328273975454), (70, 0.05163007712346614), (71, 0.02980491357610684), (72, 0.0430836704922543), (73, 0.07319786384303688), (74, 0.1659534940873187), (75, 0.04805524252058899), (76, 0.09375399876622974), (77, 0.03967225177837232), (78, 0.04263991055430013), (79, 0.03678793835341271), (80, 0.06022838670156517), (81, 0.15321856511383772), (82, 0.07031355041807727), (83, 0.058730707569876556), (84, 0.22982784767075656), (85, 0.056053147633726), (86, 0.08078452162475803), (87, 0.058730707569876556), (88, 0.06561120606131572), (89, 0.07031355041807727), (90, 0.04187609020034293), (91, 0.06781504448328635), (92, 0.14308257109546987), (93, 0.07660928255691886), (94, 0.10969113468362927), (95, 0.05734407327660557), (96, 0.024966735589369113), (97, 0.035917502324357156), (98, 0.06185645660730057), (99, 0.07031355041807727), (100, 0.058730707569876556), (101, 0.11901675533511694), (102, 0.058730707569876556), (103, 0.08078452162475803), (104, 0.030428671347565647), (105, 0.1806851601046955), (106, 0.05264172891984401), (107, 0.056053147633726), (108, 0.028330844542635996), (109, 0.08078452162475803), (110, 0.17487200975076178), (111, 0.112106295267452), (112, 0.04576123042840485), (113, 0.11468814655321113), (114, 0.024966735589369113)]\n"
     ]
    }
   ],
   "source": [
    "tfidf_model = gensim.models.TfidfModel(corpus_bow)\n",
    "corpus_tfidf = tfidf_model[corpus_bow] \n",
    "print(corpus_tfidf[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24df8cb",
   "metadata": {},
   "source": [
    "Now we train an [LDA model](https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html) with 10 topics on the TF-IDF corpus. Save it to a variable `model_lda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ded6b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 10\n",
    "\n",
    "model_lda = gensim.models.LdaModel(\n",
    "    corpus=corpus_tfidf,\n",
    "    id2word=dictionary,\n",
    "    num_topics=num_topics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91845654",
   "metadata": {},
   "source": [
    "Let's inspect the first 5 topics of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca3a357e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.002*\"race\" + 0.002*\"australia\" + 0.002*\"storm\" + 0.002*\"bill\" + 0.002*\"south\" + 0.002*\"cancer\" + 0.002*\"govern\" + 0.001*\"asic\" + 0.001*\"bank\" + 0.001*\"airlin\"'),\n",
       " (8,\n",
       "  '0.002*\"best\" + 0.002*\"team\" + 0.002*\"win\" + 0.002*\"hill\" + 0.002*\"cut\" + 0.002*\"year\" + 0.002*\"bank\" + 0.002*\"reid\" + 0.002*\"afghanistan\" + 0.001*\"oil\"'),\n",
       " (2,\n",
       "  '0.002*\"arrest\" + 0.002*\"hospit\" + 0.002*\"new\" + 0.002*\"australia\" + 0.002*\"road\" + 0.002*\"mr\" + 0.002*\"peopl\" + 0.002*\"death\" + 0.002*\"die\" + 0.002*\"whether\"'),\n",
       " (6,\n",
       "  '0.003*\"fire\" + 0.002*\"union\" + 0.002*\"india\" + 0.002*\"isra\" + 0.002*\"palestinian\" + 0.002*\"call\" + 0.002*\"commiss\" + 0.002*\"mr\" + 0.002*\"depart\" + 0.002*\"lee\"'),\n",
       " (4,\n",
       "  '0.004*\"palestinian\" + 0.003*\"isra\" + 0.003*\"arafat\" + 0.002*\"farmer\" + 0.002*\"israel\" + 0.002*\"worker\" + 0.002*\"union\" + 0.002*\"qanta\" + 0.002*\"hama\" + 0.002*\"economi\"')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lda.print_topics(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ce453",
   "metadata": {},
   "source": [
    "We see the 5 topics with the highest importance. For each topic, the 10 most important words are shown, together with their coefficient of \"alignment\" to the topic.\n",
    "\n",
    "## Document Similarity\n",
    "We now use our LDA model to compare the similarity of new documents (*queries*) to documents in our collection.\n",
    "\n",
    "First, create an index of the news articles in our corpus. Use the `MatrixSimilarity` transformation as described in gensim's [similarity queries tutorial](https://radimrehurek.com/gensim/auto_examples/core/run_similarity_queries.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4eb44cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = gensim.similarities.MatrixSimilarity(model_lda[corpus_tfidf])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7b2c1f",
   "metadata": {},
   "source": [
    "Now, write a function that takes a query string as input and returns the LDA representation for it. Make sure to apply the same preprocessing as we did to the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dabf9dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_representation(query):\n",
    "    query = preprocess(query)\n",
    "    query_bow = dictionary.doc2bow(query)\n",
    "    query_tfidf = tfidf_model[query_bow]\n",
    "    return model_lda[query_tfidf]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77753be",
   "metadata": {},
   "source": [
    "Print the top 5 most similar documents, together with their similarities, using your index created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7696f2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9509123 ['new', 'south', 'wale', 'state', 'emerg', 'servic', '(', 'se', ')', 'say', 'receiv', '5,000', 'call', 'help', 'wake', 'monday', 'fierc', 'storm', '.', 'natur', 'disast', 'area', 'declar', 'throughout', 'sydney', 'surround', 'area', 'part', 'state', 'north-west', '.', 'sydney', ',', '2,000', 'home', ',', 'mainli', 'northern', 'suburb', ',', 'remain', 'without', 'power', '.', 'se', 'spokeswoman', 'laura', 'goodin', 'say', 'sever', 'hundr', 'volunt', 'back', 'field', 'morn', '.', \"'ve\", '5,000', 'call', 'help', \"'ve\", 'complet', 'two-third', '.', \"'ve\", '800', 'volunt', 'field', 'help', 'royal', 'fire', 'servic', 'new', 'south', 'wale', 'fire', 'brigad', \"'re\", 'expect', 'job', 'complet', 'friday', ',', 'ms', 'goodin', 'said', '.', 'extens', 'storm', 'damag', 'prompt', 'warn', 'peopl', 'fals', 'claim', 'work', 'se', '.', 'warn', ',', 'fair', 'trade', 'minist', 'john', 'aquilina', ',', 'follow', 'report', 'suburb', 'hornsbi', 'peopl', 'claim', 'work', 'se', 'ask', 'payment', 'storm', 'victim', '.', 'mr', 'aquilina', 'remind', 'household', 'se', 'volunt', 'organis', 'charg', 'work', 'employ', 'sub-contractor', '.', 'suggest', 'resid', 'contact', 'polic', 'approach', 'peopl', '.', 'govern', 'also', 'warn', 'household', 'deal', 'unlicens', 'tradespeopl', '.']\n",
      "0.9083242 ['earthquak', 'measur', '4.1', 'richter', 'scale', 'shaken', 'part', 'western', 'australia', 'wheatbelt', 'overnight', '.', 'geo-scienc', 'australia', 'say', 'epicentr', 'burakin', ',', '240', 'kilometr', 'north-east', 'perth', '.', 'spokesman', 'say', 'earthquak', ',', 'occur', '12:30am', ',', 'follow', 'larger', 'quak', 'septemb', 'measur', 'five', 'richter', 'scale', '.', 'shane', 'bradford', 'ballidu', 'west', 'burakin', ',', 'say', 'quak', 'shook', 'hous', 'woke', 'sleep', '.']\n",
      "0.90804017 ['industri', 'action', 'affect', 'three', 'australia', 'biggest', 'bank', 'next', 'two', 'day', '.', 'bank', 'staff', 'westpac', 'nation', 'australia', 'bank', 'strike', 'today', '24', 'hour', ',', 'worker', 'anz', 'follow', 'suit', 'tomorrow', '.', 'action', 'member', 'financ', 'sector', 'union', 'time', 'coincid', 'bank', 'annual', 'gener', 'meet', 'part', 'ongo', 'enterpris', 'bargain', 'negoti', '.', 'union', 'geoff', 'derrick', 'say', 'strike', 'pay', '.', 'certainli', 'pay', ',', 'need', 'key', 'issu', 'us', 'around', 'workload', '.', \"'ve\", 'got', 'million', 'hour', 'overtim', 'work', 'week', 'industri', '[', ']', 'unpaid', ',', 'mr', 'derrick', 'said', '.', 'westpac', 'david', 'lord', 'say', 'today', 'action', 'unjustifi', '.', '8', 'per', 'cent', 'pay', 'increas', 'two', 'year', 'elig', 'staff', 'tabl', ',', 'gener', 'pay', 'offer', '.', 'would', 'also', 'like', 'introduc', 'number', 'initi', 'assist', 'staff', 'balanc', 'particular', 'work', 'famili', 'life', ',', 'would', 'like', 'deal', 'union', ',', 'mr', 'lord', 'said', '.', 'would', 'like', 'union', 'come', 'back', 'negoti', 'tabl', 'rather', 'continu', 'pr', 'stunt', '.', 'mr', 'lord', 'say', 'conting', 'plan', 'place', 'ensur', 'branch', 'stay', 'open', '.', 'hope', 'offer', 'normal', 'bank', 'servic', 'custom', ',', 'said', '.']\n",
      "0.9066454 ['geoff', 'huegil', 'continu', 'record-break', 'way', 'world', 'cup', 'short', 'cours', 'swim', 'melbourn', ',', 'better', 'australian', 'record', '100', 'metr', 'butterfli', '.', 'huegil', 'beat', 'fellow', 'australian', 'michael', 'klim', ',', 'back', 'last', 'night', 'set', 'world', 'record', '50', 'metr', 'butterfli', '.']\n",
      "0.9039321 ['mileston', 'histori', 'radio', 'featur', 'six', 'abc', 'radio', 'network', 'today', 'mark', '100', 'year', 'sinc', 'guglielmo', 'marconi', 'first', 'transatlant', 'broadcast', 'signal', 'birth', 'radio', '.', 'celebr', ',', 'six', 'radio', 'network', '-', 'abc', 'fm', ',', 'local', 'radio', ',', 'newsradio', ',', 'radio', 'australia', ',', 'radio', 'nation', 'tripl', 'j', '-', 'broadcast', 'five-minut', 'simulcast', '11:55am', '(', 'aedt', ')', 'morn', '.', 'play', 'audio', 'top', '10', 'radio', 'news', 'stori', 'past', '100', 'year', ',', 'vote', 'listen', '.', 'includ', 'coverag', 'world', 'war', 'ii', ',', 'assassin', 'presid', 'john', 'f', 'kennedi', ',', 'land', 'moon', 'terrorist', 'attack', 'septemb', '11', '.']\n"
     ]
    }
   ],
   "source": [
    "sims = index[get_lda_representation(\"Sydney is a harbour city\")]\n",
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "for doc_position, doc_score in sims[:5]:\n",
    "    print(doc_score, articles[doc_position])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e05dba",
   "metadata": {},
   "source": [
    "Run your code again, now training an LDA model with 100 topics. Do you see a qualitative difference in the top-5 most similar documents?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
