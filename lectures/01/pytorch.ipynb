{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47b1b6f",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "In this exercise, we will look at some basic functionality of PyTorch. Your are free to use other DL frameworks for your exercises and your project. However, the master solutions and code examples will be in PyTorch.\n",
    "\n",
    "The [PyTorch documentation](https://pytorch.org/docs/stable/index.html) offers information on its functionality. A lot of the time, your specific question will also have been asked on the [PyTorch Forum](https://discuss.pytorch.org/), often with competent answers by the core developers (Google will find the relevant thread for you).\n",
    "\n",
    "First, we have to install PyTorch. We will install the basic version for this exercise. For your project, if you want to run on a GPU, you'll have to make sure to have a PyTorch version installed that is compatible with the CUDA version of your NVIDIA drivers. PyTorch has an [installation guide](https://pytorch.org/get-started/locally/) that will help you with getting the right version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a1efca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.61.0 requires numpy<2.2,>=1.24, but you have numpy 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U numpy\n",
    "%pip install -q torch ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c05320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec5791",
   "metadata": {},
   "source": [
    "## Tensor operations\n",
    "Most of PyTorch's operations have the same name as in NumPy. The basic object for storing data is the `torch.tensor`, the equivalent of the `np.array`. With the help of the [Tensor tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html), do the following:\n",
    "\n",
    "- Create a `torch.tensor` with the elements `[[1, 2], [3, 4]]`\n",
    "- Create a tensor of ones/zeros with the same shape and dtype\n",
    "- Create a random tensor of the same shape\n",
    "- Print the tensor's shape, data type and device\n",
    "- Try to move it to the GPU\n",
    "- For Mac users: Try to move it to [MPS](https://pytorch.org/docs/stable/notes/mps.html)\n",
    "- Check out indexing/slicing operations, and how you can assign values to a slice.\n",
    "- Combine tensors with `torch.cat` and `torch.stack`. What are the differences?\n",
    "- Multiply tensors, element-wise and with matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48a760-052f-477a-acf2-b6e972e1b2fe",
   "metadata": {},
   "source": [
    "### Instantiating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c90229fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "torch.Size([2, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "x_data = torch.tensor(data, dtype=torch.float)\n",
    "print(x_data)\n",
    "print(x_data.shape)\n",
    "print(x_data.dtype)\n",
    "print(x_data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78420c3a-68ca-4c7c-bd5f-9c3e4e4d28f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "torch.Size([2, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.ones((2, 2), dtype=torch.float)\n",
    "print(x_data)\n",
    "print(x_data.shape)\n",
    "print(x_data.dtype)\n",
    "print(x_data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d40da51-3a20-46d5-9bb4-4655eea7633f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "torch.Size([2, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.zeros((2, 2), dtype=torch.float)\n",
    "print(x_data)\n",
    "print(x_data.shape)\n",
    "print(x_data.dtype)\n",
    "print(x_data.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18a1714e-4be9-4fad-991d-2967eb1804bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7517, 0.9648],\n",
      "        [0.4269, 0.5382]])\n",
      "torch.Size([2, 2])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "x_data = torch.rand((2, 2), dtype=torch.float)\n",
    "print(x_data)\n",
    "print(x_data.shape)\n",
    "print(x_data.dtype)\n",
    "print(x_data.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28ac800-6de7-4016-a41c-4f64570f3c0c",
   "metadata": {},
   "source": [
    "### Moving tensor to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fab37d9-ab47-4af8-a295-687aa77a7f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "  x_data = x_data.to('cuda')\n",
    "  print(x_data.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688ce2b8-978f-4dea-8965-39ed2496b221",
   "metadata": {},
   "source": [
    "### Concatenating and stacking tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3babec0d-e59a-477c-ae97-372adabb341a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7517, 0.9648],\n",
      "        [0.4269, 0.5382],\n",
      "        [0.7517, 0.9648],\n",
      "        [0.4269, 0.5382],\n",
      "        [0.7517, 0.9648],\n",
      "        [0.4269, 0.5382]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat([x_data, x_data, x_data], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b300816-acb1-41df-9749-dcfe30d6b870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7517, 0.9648],\n",
      "         [0.4269, 0.5382]],\n",
      "\n",
      "        [[0.7517, 0.9648],\n",
      "         [0.4269, 0.5382]],\n",
      "\n",
      "        [[0.7517, 0.9648],\n",
      "         [0.4269, 0.5382]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.stack([x_data, x_data, x_data], dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4367e07-b5aa-46d1-976c-81d5eaeb5d38",
   "metadata": {},
   "source": [
    "### Mutliplying tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3805071-1af6-4dbf-8b39-e7c2b615314d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5650, 0.9309],\n",
      "        [0.1823, 0.2896]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(x_data * x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "975d74e6-a339-46cb-9a9e-f85c88b50d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4959, 0.8401],\n",
      "        [0.8401, 0.4719]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(x_data @ x_data.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36d91f",
   "metadata": {},
   "source": [
    "## Neural Network Basics\n",
    "Solve the followings tasks with the help of the [Neural networks tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
    "\n",
    "The `nn.Module` is the basic class for layers, networks and models. All parameters of an `nn.Module` are automatically discovered by PyTorch and updated by back-propagation.\n",
    "\n",
    "First, define a neural network (as a subclass of `nn.Module`) with two linear layers and a ReLU non-linearity in between. Make the input, output, and inner dimensions parameters of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a5284525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc6e17c6-798e-452b-b55e-13104f9f75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16\n",
    "output_dim = 8\n",
    "inner_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e66e191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self, i_dim: int, o_dim: int, n_dim: int):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(i_dim, n_dim)\n",
    "        self.fc2 = nn.Linear(n_dim, o_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x1 = F.relu(self.fc1(data))\n",
    "        output = F.relu(self.fc2(x1))\n",
    "        return output\n",
    "\n",
    "model = Network(input_dim, output_dim, inner_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eae143",
   "metadata": {},
   "source": [
    "Move the entire network to the GPU/MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f976d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22867b",
   "metadata": {},
   "source": [
    "Print the parameters of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "77e3383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 1.1357e-01, -1.2461e-01, -9.6427e-02,  2.1063e-01,  2.4405e-01,\n",
      "          1.9475e-01,  1.4092e-01,  1.0269e-01, -2.1790e-01, -6.4003e-02,\n",
      "          3.8139e-02, -2.2471e-01,  1.2052e-01, -2.2103e-01,  2.0432e-01,\n",
      "          1.8947e-01],\n",
      "        [-1.4985e-02,  1.0859e-01,  1.4339e-01, -7.6691e-02, -1.3636e-01,\n",
      "          1.6803e-01,  2.4665e-02, -2.3384e-02, -2.0710e-01, -8.8228e-02,\n",
      "         -1.6718e-01, -5.9927e-02, -1.7012e-01, -2.3862e-01,  1.0852e-02,\n",
      "          9.2305e-02],\n",
      "        [ 1.5696e-01, -1.4668e-01, -7.9758e-02, -2.3428e-01, -1.7764e-01,\n",
      "          2.4710e-01,  1.5189e-01, -2.1949e-01,  8.2772e-02, -2.3328e-01,\n",
      "          2.0154e-01,  2.2618e-01,  1.9442e-01,  2.2126e-02,  1.1351e-01,\n",
      "          1.6278e-01],\n",
      "        [ 2.4086e-01, -1.4690e-01,  5.7770e-02,  1.9331e-01,  1.9940e-01,\n",
      "         -1.4034e-01,  8.5880e-02, -8.5437e-02,  1.3639e-01, -2.3808e-01,\n",
      "         -1.0914e-01, -8.5457e-02, -1.1195e-01, -1.9593e-01, -1.6752e-01,\n",
      "          1.6535e-01],\n",
      "        [-9.8385e-02,  1.6951e-01, -2.1106e-01,  1.8107e-01,  1.3611e-01,\n",
      "         -6.4759e-02, -6.5246e-02,  1.3537e-01,  4.4717e-02,  1.2485e-01,\n",
      "         -1.3467e-01,  1.1524e-02,  6.0026e-02, -2.2233e-01,  2.4470e-01,\n",
      "          1.3355e-01],\n",
      "        [ 1.9889e-02,  4.7768e-02, -1.0953e-01,  1.0871e-02, -2.3598e-01,\n",
      "          9.8826e-03, -1.9504e-01,  1.5585e-01,  8.8538e-02,  6.0841e-02,\n",
      "         -1.8059e-03, -1.5278e-01,  2.4065e-01,  1.0258e-01,  2.3030e-01,\n",
      "         -2.6238e-02],\n",
      "        [-2.9328e-03, -1.9411e-01,  1.3309e-01, -7.0870e-02,  9.9676e-02,\n",
      "          1.2020e-01,  1.4461e-01,  1.1542e-02, -2.4494e-01,  2.3719e-01,\n",
      "          1.3488e-01, -1.6306e-02, -1.7885e-01, -2.4679e-01,  1.7530e-01,\n",
      "          6.9536e-02],\n",
      "        [-7.7852e-02,  7.1861e-02, -2.3765e-01, -1.5926e-01,  1.0475e-01,\n",
      "          4.4087e-03, -1.9855e-01,  3.3720e-02, -1.8242e-02, -9.4956e-02,\n",
      "         -2.4379e-01,  2.0480e-01,  7.0530e-02,  1.9668e-01, -7.3408e-02,\n",
      "          1.4267e-01],\n",
      "        [ 6.3533e-02, -1.0432e-01, -3.5812e-02,  1.6698e-01,  9.8556e-02,\n",
      "         -1.8402e-01,  2.0912e-01,  2.7026e-02,  9.0093e-02, -7.1071e-03,\n",
      "          2.4260e-01,  2.1705e-01,  1.2389e-01,  2.4071e-01,  1.2440e-01,\n",
      "          2.4143e-01],\n",
      "        [ 8.0557e-02,  1.6044e-01,  1.7626e-01, -3.6648e-02,  1.3255e-01,\n",
      "          4.2237e-02,  1.5135e-01,  5.8922e-02, -9.5199e-03, -1.4619e-01,\n",
      "         -2.1097e-01, -6.0803e-02,  1.3341e-01,  1.1522e-01, -1.8567e-01,\n",
      "          1.4886e-01],\n",
      "        [-8.9640e-02,  2.2402e-01,  1.2385e-01, -1.9725e-01, -2.2232e-01,\n",
      "          8.7428e-02,  2.0645e-01,  1.4495e-01,  1.6853e-01,  1.5377e-01,\n",
      "         -3.7984e-02,  1.3473e-01, -1.5837e-01,  1.9624e-01, -1.4119e-01,\n",
      "          2.4726e-01],\n",
      "        [ 2.8030e-02,  1.9739e-01, -1.0818e-01, -1.6421e-01,  1.7582e-01,\n",
      "         -2.1906e-01,  1.4535e-01,  2.4422e-01,  2.9875e-02,  6.0096e-02,\n",
      "         -1.1873e-01, -8.5181e-02,  2.2379e-01,  1.3501e-01, -6.9239e-02,\n",
      "          1.3446e-01],\n",
      "        [-2.3218e-01,  2.3623e-01,  1.0609e-01, -1.5327e-01, -3.3638e-02,\n",
      "          1.5444e-01,  8.9335e-02,  2.1126e-03,  7.9194e-02, -4.5930e-02,\n",
      "         -9.0070e-02,  1.1506e-01, -1.9522e-01,  1.3564e-01, -4.9090e-03,\n",
      "         -2.0284e-01],\n",
      "        [ 1.3115e-01, -1.4936e-01,  2.7614e-02, -1.8684e-01,  6.8618e-02,\n",
      "         -1.8598e-01,  1.6658e-01,  1.6320e-01, -2.1771e-01, -3.5120e-02,\n",
      "         -1.8402e-01, -1.1499e-01,  1.2553e-02,  6.7629e-02, -7.5029e-03,\n",
      "          1.7881e-01],\n",
      "        [ 9.6184e-04,  2.0292e-01, -6.3427e-02,  7.2621e-02, -6.0413e-02,\n",
      "         -1.6108e-01,  1.4160e-01,  1.4253e-01, -1.4528e-01,  2.0695e-01,\n",
      "         -2.2129e-01, -6.3088e-02,  1.4422e-01, -9.9710e-02,  1.2589e-01,\n",
      "         -4.3955e-02],\n",
      "        [-2.2654e-02,  1.2455e-01, -1.5479e-01,  1.0318e-01, -2.2972e-02,\n",
      "          1.8331e-01, -1.6313e-01,  1.4137e-01,  1.3553e-01,  7.0364e-02,\n",
      "         -4.5781e-02,  1.3599e-01, -1.2373e-02,  8.6288e-02,  1.8256e-01,\n",
      "          4.7252e-03],\n",
      "        [ 1.2918e-01, -1.9418e-01, -1.3976e-01,  1.5611e-01, -7.5578e-02,\n",
      "          1.5098e-01,  9.3801e-02,  2.0245e-01, -2.4686e-01,  1.7295e-01,\n",
      "         -4.1071e-02, -1.3326e-01,  2.3300e-01,  1.1283e-01,  1.9102e-01,\n",
      "         -1.6842e-01],\n",
      "        [ 1.7731e-01,  1.9101e-01,  7.6932e-02, -3.2585e-02, -1.2984e-01,\n",
      "         -2.0703e-02, -2.0440e-01,  1.3314e-01,  5.1622e-02,  1.6789e-01,\n",
      "          1.9701e-01,  2.4701e-02, -9.0160e-02,  3.9120e-02,  1.3465e-01,\n",
      "         -6.6453e-02],\n",
      "        [ 1.7586e-01, -1.3473e-01,  2.0711e-01, -1.5653e-01, -1.7545e-01,\n",
      "         -1.3699e-01,  1.5417e-01, -1.1056e-01, -9.1637e-02, -2.2610e-01,\n",
      "         -5.2566e-02, -2.1824e-02, -3.2631e-02, -5.4722e-02,  9.2242e-02,\n",
      "         -4.0120e-02],\n",
      "        [ 4.8689e-02, -1.2860e-01, -1.2532e-01,  5.8299e-02,  1.6404e-01,\n",
      "         -1.5731e-01, -1.5049e-01,  7.7088e-02, -2.1988e-01,  1.3463e-01,\n",
      "         -1.0612e-01,  3.6076e-03,  1.3981e-01, -2.8578e-02,  2.0774e-01,\n",
      "          1.3350e-01],\n",
      "        [ 1.7194e-01, -8.9103e-02, -1.1388e-01, -1.3606e-01,  7.7977e-03,\n",
      "          2.1989e-01,  1.2666e-01, -1.9614e-01, -1.6502e-01, -1.6922e-01,\n",
      "         -6.3296e-02,  2.1751e-01,  2.0607e-01,  1.4839e-01, -1.4602e-01,\n",
      "          2.0816e-01],\n",
      "        [-2.4461e-01, -1.7618e-01, -8.1433e-02,  9.8258e-05, -2.3555e-01,\n",
      "          6.6730e-02, -1.1809e-01, -1.5859e-01, -5.3638e-02, -1.4305e-02,\n",
      "          1.7495e-01,  1.6761e-01, -1.9015e-01,  1.8138e-01, -7.1366e-02,\n",
      "          3.5620e-02],\n",
      "        [ 2.1671e-01,  4.4625e-02, -4.5114e-02,  2.3954e-01, -8.3690e-02,\n",
      "         -9.8411e-02,  8.5431e-02, -2.3704e-01, -2.2401e-02,  1.4973e-01,\n",
      "         -1.3290e-01,  3.2258e-02,  2.0218e-01,  2.2195e-01,  2.2846e-01,\n",
      "         -1.7976e-01],\n",
      "        [-7.3971e-02,  9.8251e-02, -1.9084e-01,  2.3071e-01, -1.3402e-01,\n",
      "          5.6694e-02,  2.4302e-01,  1.1853e-02,  1.5930e-01,  1.2188e-01,\n",
      "          1.0345e-01,  2.0153e-01,  5.2616e-02, -1.5163e-01, -3.7988e-02,\n",
      "         -8.9882e-02],\n",
      "        [-2.7679e-02, -1.5989e-01, -2.3232e-01,  2.3007e-01, -4.3950e-02,\n",
      "          1.5582e-01,  2.5023e-02,  4.9099e-02, -5.6481e-02,  1.6744e-01,\n",
      "          1.7080e-01,  2.1423e-01, -1.2943e-01, -5.7892e-02, -1.0025e-01,\n",
      "         -1.6754e-01],\n",
      "        [-4.5436e-02,  1.5204e-01, -4.7896e-02,  5.0709e-02,  8.9979e-02,\n",
      "          1.3426e-01,  1.7435e-01,  1.1273e-01,  2.2425e-01,  1.7132e-01,\n",
      "          5.4097e-02,  4.2720e-02, -3.7826e-02,  1.5326e-01,  9.9741e-03,\n",
      "         -1.3969e-01],\n",
      "        [-1.1037e-01, -1.1124e-01,  2.0303e-01,  2.1134e-01, -1.2099e-01,\n",
      "         -2.3125e-01, -2.3658e-01, -2.3187e-01,  9.3251e-02, -5.8886e-02,\n",
      "         -8.5745e-02, -1.9159e-01, -2.2280e-01,  4.0235e-02,  7.6502e-02,\n",
      "          1.1277e-01],\n",
      "        [-2.3311e-01, -1.5941e-01,  1.3495e-01,  7.8486e-02,  5.9067e-02,\n",
      "         -1.5314e-01, -4.2650e-02,  1.1540e-01,  9.7514e-02,  1.2570e-01,\n",
      "          1.7931e-01, -1.6603e-02, -1.7339e-01, -6.3966e-02, -2.4419e-01,\n",
      "         -1.9727e-01],\n",
      "        [ 2.9402e-02, -1.4043e-01, -1.2169e-01,  1.0017e-01,  1.8581e-01,\n",
      "         -2.4428e-01,  1.2787e-01,  2.4904e-01,  2.3602e-01, -7.1074e-02,\n",
      "          2.1170e-01, -1.1208e-01, -6.7426e-02,  2.4670e-02,  2.3985e-02,\n",
      "         -2.3519e-01],\n",
      "        [-1.6177e-02,  2.5157e-02,  2.2028e-01, -1.4824e-01, -5.5478e-02,\n",
      "          1.5915e-01, -2.1268e-01,  3.1262e-02,  2.2066e-01, -8.5082e-02,\n",
      "          1.7577e-01,  3.8138e-02, -1.7585e-02, -8.8072e-02, -2.1463e-01,\n",
      "         -9.6340e-02],\n",
      "        [-1.4262e-03, -1.5915e-01, -3.2030e-02,  6.3003e-02, -4.3614e-02,\n",
      "         -1.4917e-01, -1.0921e-02,  4.8253e-02,  1.4480e-01, -2.6899e-03,\n",
      "         -1.5597e-01,  8.0076e-02,  1.9807e-01, -2.1424e-01, -8.9598e-02,\n",
      "          1.1263e-01],\n",
      "        [-1.1291e-01,  2.4180e-01,  3.3307e-02,  1.9379e-01,  1.7573e-01,\n",
      "          2.1376e-01,  1.5848e-01,  1.4551e-01,  2.0409e-01, -8.0689e-02,\n",
      "          9.4236e-02, -2.3548e-01, -1.9569e-02,  1.2451e-01,  1.2240e-01,\n",
      "         -2.3303e-01]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([-0.0835, -0.0490,  0.1702, -0.0313,  0.1640,  0.1611,  0.1046,  0.0776,\n",
      "         0.0879, -0.1913, -0.2431,  0.2161,  0.0435,  0.1203,  0.0930, -0.0091,\n",
      "        -0.2097,  0.0418,  0.1230, -0.0166,  0.0245,  0.1981,  0.0575,  0.2252,\n",
      "         0.0303,  0.0974, -0.1837, -0.2481,  0.0273, -0.1611,  0.0095, -0.1086],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[-0.1204, -0.0945, -0.0402,  0.0117,  0.1409,  0.0528,  0.1671,  0.0090,\n",
      "          0.0516, -0.0787, -0.1134,  0.0428,  0.0986, -0.1149,  0.0392, -0.0052,\n",
      "          0.1098, -0.0747,  0.1429, -0.1473, -0.1589, -0.1562, -0.0589,  0.1548,\n",
      "          0.1689,  0.0975,  0.0568, -0.0153,  0.1387,  0.1696, -0.1335,  0.1287],\n",
      "        [ 0.0795, -0.0228, -0.0630,  0.0258,  0.1110, -0.1540, -0.0412,  0.1205,\n",
      "          0.0308,  0.0193,  0.1602, -0.1608,  0.1120, -0.0166,  0.1384, -0.0368,\n",
      "          0.1535, -0.1524, -0.1104,  0.1338,  0.1479, -0.0774,  0.0006, -0.0307,\n",
      "         -0.0429, -0.0473, -0.1082, -0.0672,  0.1370,  0.1697, -0.1090, -0.0087],\n",
      "        [ 0.0578, -0.0448, -0.0221, -0.0987, -0.0801,  0.0945,  0.1655,  0.0004,\n",
      "         -0.0453, -0.1217, -0.1054,  0.1423,  0.1231,  0.1491, -0.0580, -0.0107,\n",
      "         -0.0194,  0.1706, -0.0161,  0.1522,  0.0820,  0.1091,  0.0374, -0.0336,\n",
      "          0.0321,  0.1170,  0.0297,  0.0806,  0.0506,  0.1018,  0.1277, -0.0616],\n",
      "        [ 0.0797,  0.1524,  0.1530, -0.0774,  0.1265,  0.0780,  0.0277,  0.1346,\n",
      "          0.1324,  0.0900,  0.1560, -0.0487, -0.0386, -0.1012, -0.0636,  0.1094,\n",
      "         -0.1559,  0.0162, -0.0830,  0.0673,  0.0361, -0.0314, -0.0276,  0.0105,\n",
      "         -0.0404, -0.1226, -0.0968,  0.1505, -0.0669,  0.1382,  0.1502, -0.0555],\n",
      "        [-0.0762, -0.1231,  0.0096,  0.1495, -0.1483, -0.1599,  0.0972,  0.0919,\n",
      "          0.0522,  0.0586, -0.1554, -0.1547, -0.1540,  0.1663, -0.0738, -0.1076,\n",
      "         -0.1583, -0.0122,  0.0935,  0.0607,  0.0007, -0.0986,  0.0868,  0.1148,\n",
      "         -0.1136,  0.1441, -0.1446, -0.1044, -0.0863, -0.1684,  0.1138, -0.1631],\n",
      "        [-0.0831, -0.1660, -0.1323,  0.1400, -0.0867, -0.0410,  0.0251, -0.0592,\n",
      "         -0.0167,  0.0058, -0.1056,  0.1614, -0.0626, -0.0347,  0.0260,  0.1330,\n",
      "          0.0639, -0.0683, -0.1515, -0.1498, -0.0777,  0.1245, -0.1218, -0.1058,\n",
      "          0.0764, -0.1007, -0.1741,  0.0383, -0.0273, -0.1566,  0.1751,  0.1674],\n",
      "        [-0.1693,  0.0119, -0.1096,  0.0131, -0.0796,  0.0124, -0.0883,  0.0379,\n",
      "         -0.1036,  0.1748, -0.1386, -0.1145,  0.0830, -0.1285, -0.1426, -0.0992,\n",
      "          0.0222, -0.1360,  0.0570, -0.1675,  0.0997, -0.0013,  0.0762, -0.0245,\n",
      "          0.0286,  0.1260,  0.0613, -0.0370,  0.1004,  0.0057,  0.0072, -0.1247],\n",
      "        [ 0.1050,  0.0231,  0.1380, -0.0619,  0.0314, -0.1731, -0.1665,  0.0605,\n",
      "         -0.0826,  0.1373, -0.1654,  0.0102, -0.0320, -0.0106, -0.1295,  0.0050,\n",
      "          0.1142, -0.0355, -0.1482, -0.0431,  0.1043,  0.0376, -0.1548, -0.0045,\n",
      "          0.0548,  0.0513,  0.0398, -0.1263,  0.0671, -0.1434,  0.1269, -0.1319]],\n",
      "       device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([ 0.1121,  0.1359, -0.1371,  0.0137, -0.1353,  0.0395,  0.1409, -0.0067],\n",
      "       device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f403132",
   "metadata": {},
   "source": [
    "Run a single forward-pass with a random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f3370725",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(input_dim).to('cuda')\n",
    "output = model.forward(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d2cb7",
   "metadata": {},
   "source": [
    "Define a `nn.MSELoss` and a random target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd1983de",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.rand(output_dim).to('cuda')\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39785fbe",
   "metadata": {},
   "source": [
    "Compute the loss and run backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "53d5cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.bias.grad before backward\n",
      "None\n",
      "fc1.bias.grad after backward\n",
      "tensor([ 0.0000,  0.0000,  0.0000, -0.0186,  0.0435, -0.0100,  0.0000,  0.0070,\n",
      "         0.0000,  0.0000,  0.0000, -0.0166, -0.0069,  0.0113,  0.0352,  0.0000,\n",
      "         0.0000,  0.0000,  0.0088,  0.0000,  0.0000,  0.0000, -0.0028,  0.0272,\n",
      "         0.0000, -0.0173,  0.0000, -0.0100, -0.0082,  0.0000, -0.0437,  0.0064],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, target)\n",
    "\n",
    "model.zero_grad()     # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('fc1.bias.grad before backward')\n",
    "print(model.fc1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('fc1.bias.grad after backward')\n",
    "print(model.fc1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278bd02",
   "metadata": {},
   "source": [
    "Update the parameters of your network with a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4fe16c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.bias before update\n",
      "Parameter containing:\n",
      "tensor([-0.0835, -0.0490,  0.1702, -0.0213,  0.1640,  0.1711,  0.1046,  0.0776,\n",
      "         0.0779, -0.2013, -0.2531,  0.2261,  0.0535,  0.1303,  0.0930, -0.0091,\n",
      "        -0.2097,  0.0518,  0.1130, -0.0166,  0.0245,  0.1981,  0.0575,  0.2252,\n",
      "         0.0303,  0.1074, -0.1837, -0.2381,  0.0373, -0.1711,  0.0095, -0.0986],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "fc1.bias after update\n",
      "Parameter containing:\n",
      "tensor([-0.0835, -0.0490,  0.1702, -0.0211,  0.1635,  0.1712,  0.1046,  0.0775,\n",
      "         0.0779, -0.2013, -0.2531,  0.2263,  0.0536,  0.1302,  0.0926, -0.0091,\n",
      "        -0.2097,  0.0518,  0.1129, -0.0166,  0.0245,  0.1981,  0.0576,  0.2249,\n",
      "         0.0303,  0.1076, -0.1837, -0.2380,  0.0374, -0.1711,  0.0099, -0.0986],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('fc1.bias before update')\n",
    "print(model.fc1.bias)\n",
    "\n",
    "learning_rate = 0.01\n",
    "for f in model.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)\n",
    "\n",
    "print('fc1.bias after update')\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927bd19f",
   "metadata": {},
   "source": [
    "Use the `AdamOptimizer` instead to update your parameters (see the [torch.optim documentation](https://pytorch.org/docs/stable/optim.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32fa210d-b1a0-4067-a354-2cdd9749d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "054db4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.bias before update\n",
      "Parameter containing:\n",
      "tensor([-0.0835, -0.0490,  0.1702, -0.0313,  0.1640,  0.1611,  0.1046,  0.0776,\n",
      "         0.0879, -0.1913, -0.2431,  0.2161,  0.0435,  0.1203,  0.0930, -0.0091,\n",
      "        -0.2097,  0.0418,  0.1230, -0.0166,  0.0245,  0.1981,  0.0575,  0.2252,\n",
      "         0.0303,  0.0974, -0.1837, -0.2481,  0.0273, -0.1611,  0.0095, -0.1086],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "fc1.bias after update\n",
      "Parameter containing:\n",
      "tensor([-0.0835, -0.0490,  0.1702, -0.0213,  0.1640,  0.1711,  0.1046,  0.0776,\n",
      "         0.0779, -0.2013, -0.2531,  0.2261,  0.0535,  0.1303,  0.0930, -0.0091,\n",
      "        -0.2097,  0.0518,  0.1130, -0.0166,  0.0245,  0.1981,  0.0575,  0.2252,\n",
      "         0.0303,  0.1074, -0.1837, -0.2381,  0.0373, -0.1711,  0.0095, -0.0986],\n",
      "       device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "print('fc1.bias before update')\n",
    "print(model.fc1.bias)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print('fc1.bias after update')\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caf00f9-fe6c-4717-8b87-322784696871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
